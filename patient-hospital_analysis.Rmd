---
title: "Diabetes patients analysis"
author: "Harold Armando Achicanoy Estrella"
date: "11/28/2020"
output: html_document
---

The main objective of this analysis consists of identifying the variables that contribute the most to explain why some patients reconsulted after the application of diabetes treatments. The dataset is composed of hospital records from 130 units from the hospital network in the USA through the period 1999-2008.

Understanding the readmission process causes will help doctors to support decision making on how to address and treat diabetes patients.

The carried analysis uses the **Spark 2.1.0** framework. The machine configuration is as follows: MacBook Pro (13-inch, Mid 2012), Processor: 2.5 GHz Intel Core i5, RAM: 16 GB.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# R options
options(warn = -1, scipen = 999)
if(!require(pacman)){install.packages('pacman')}
suppressMessages(library(pacman))
suppressMessages(pacman::p_load(tidyverse, vroom, psych, caret, corrplot, fastcluster, sparklyr))
```

The structure of this rmarkdown notebook is compiled by sections of obtain, treat, organize, describe, and understand the diabetes data.

## Obtain the data

The first step consists in obtain the data from the web source, unzip the compressed file, and read it using a fast library to load text files in R.

```{r, include=TRUE}
## --------------------------------------------------- ##
## Obtain the data
## --------------------------------------------------- ##
if(!file.exists(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'))){
  ## Download data
  url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip'
  download.file(url, destfile = paste0(getwd(),'/dataset_diabetes.zip'))
  ## Unzip files
  unzip(paste0(getwd(),'/dataset_diabetes.zip'))
  file.remove(paste0(getwd(),'/dataset_diabetes.zip'))
  ## Load the data
  tbl <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'), delim = ',')
} else {
  ## Load the data
  tbl <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'), delim = ',')
}
## Replace '?' character by NA's
tbl <- tbl %>% dplyr::na_if(y = '?')
```

The dataset is conformed by 101766 patients-records with 50 attributes of information.

```{r dimension}
cat(paste0('The dataset is conformed by: ',dim(tbl), ' records vs features'))
```

## Data pre-processing

The data pre-processing consists in apply some operations to:
* Identify and remove features without or low variance
* Replace codes by the right categories in some categorical variables
* Regroup many labels into meaningful categories
* Identify and remove features with more than 25% of missing data
* Check the data types
* Create or modify variables

```{r preprocessing, echo=FALSE}
## --------------------------------------------------- ##
## Data pre-processing
## --------------------------------------------------- ##
## Identify and remove variables without or with low variance
zvar <- tbl %>% caret::nzv()
cat(paste0('The following features were removed: ',names(tbl)[zvar], ' due to the low or insignificant variance\n'))
tbl  <- tbl[,-zvar]; rm(zvar)

## Replace the codes by the right categories to the *admission* variables
# Load ID identifiers
idi  <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/IDs_mapping.csv'), delim = ',')
mtch <- which(is.na(idi$admission_type_id))
# admision_type_id
idi1 <- idi[1:(mtch[1]-1),]
# discharge_disposition_id
idi2 <- idi[(mtch[1]+1):(mtch[2]-1),]
names(idi2) <- as.character(idi2[1,])
idi2 <- idi2[-1,]
# admission_source_id
idi3 <- idi[(mtch[2]+1):nrow(idi),]
names(idi3) <- as.character(idi3[1,])
idi3 <- idi3[-1,]; rm(mtch)

tbl$admission_type_id <- factor(tbl$admission_type_id)
levels(tbl$admission_type_id) <- idi1$description
levels(tbl$admission_type_id)[levels(tbl$admission_type_id) %in% c('NULL','Not Available')] <- NA
# Create a new category which comprises the levels: 'Newborn','Trauma Center','Not Mapped'
levels(tbl$admission_type_id)[levels(tbl$admission_type_id) %in% c('Newborn','Trauma Center','Not Mapped')] <- 'Other'

tbl$discharge_disposition_id <- factor(tbl$discharge_disposition_id)
levels(tbl$discharge_disposition_id) <- idi2$description[match(levels(tbl$discharge_disposition_id), idi2$discharge_disposition_id)]
levels(tbl$discharge_disposition_id)[levels(tbl$discharge_disposition_id) %in% c('NULL','Not Available')] <- NA
# Create new categories: Discharged, Expired, Hospice, and Admitted
levels(tbl$discharge_disposition_id)[grep(pattern = '[dD][iI][sS][cC][hH][aA][rR][gG][eE][dD]', x = levels(tbl$discharge_disposition_id))] <- 'Discharged'
levels(tbl$discharge_disposition_id)[grep(pattern = '[eE][xX][pP][iI][rR][eE][dD]', x = levels(tbl$discharge_disposition_id))] <- 'Expired'
levels(tbl$discharge_disposition_id)[grep(pattern = '[hH][oO][sS][pP][iI][cC][eE]', x = levels(tbl$discharge_disposition_id))] <- 'Hospice'
levels(tbl$discharge_disposition_id)[c(2,3,5)] <- 'Admitted'

tbl$admission_source_id <- factor(tbl$admission_source_id)
levels(tbl$admission_source_id) <- idi3$description[match(levels(tbl$admission_source_id), idi3$admission_source_id)]
levels(tbl$admission_source_id)[levels(tbl$admission_source_id) %in% c('NULL','Not Available')] <- NA
# Create new categories: Transfer, Referral, and Other
levels(tbl$admission_source_id)[grep(pattern = '[tT][rR][aA][nN][sS][fF][eE][rR]', x = levels(tbl$admission_source_id))] <- 'Transfer'
levels(tbl$admission_source_id)[grep(pattern = '[rR][eE][fF][eE][rR][rR][aA][lL]', x = levels(tbl$admission_source_id))] <- 'Referral'
levels(tbl$admission_source_id)[4:8] <- 'Other'
rm(idi, idi1, idi2, idi3)

## Omit Unknown category in gender
# It only has 3 registers
cat(paste0('Omit Unknown category in gender. The distribution of this feature is as follows\n'))
table(tbl$gender)
tbl$gender[grep(pattern = 'Unknown', x = tbl$gender)] <- NA

## Identify variables with more than 25% of missing data
msg <- tbl %>%
  apply(X = ., MARGIN = 2, function(x){sum(is.na(x))/nrow(.)}) %>%
  sort(decreasing = T) %>%
  .[. > 0.25]
cat(paste0('The following features were removed: ',names(msg), ' due to high amount of missing data\n'))

## Remove variables with more than 25% of missing data
tbl <- tbl[,-which(names(tbl) %in% names(msg))]; rm(msg)

## Create a new feature: How many times the same patient have visited the hospital?
# Select the ones with the maximum number of days interned in the hospital
visits <- tbl$patient_nbr %>% table %>% sort(decreasing = T) %>% base::as.data.frame()
names(visits)[1] <- 'patient_nbr'
visits$patient_nbr <- visits$patient_nbr %>% as.character() %>% as.numeric()
unq_vs <- visits %>% dplyr::filter(Freq == 1)
visits <- visits %>% dplyr::filter(Freq > 1)

tbl_unq <- tbl %>% dplyr::filter(patient_nbr %in% unq_vs$patient_nbr)
tbl_unq$number_visits <- 1

tbl_dup <- 1:nrow(visits) %>%
  purrr::map(.f = function(i){
    df <- tbl %>%
      dplyr::filter(patient_nbr == visits$patient_nbr[i]) %>%
      .[which.max(.$time_in_hospital)[1],]
    df$number_visits <- visits$Freq[i]
    return(df)
  }) %>%
  dplyr::bind_rows()

tbl <- rbind(tbl_dup, tbl_unq)
# Number of unique patients
cat(paste0('The number of unique patients after removing duplicated information is: ',nrow(tbl), '\n'))
rm(tbl_dup, tbl_unq, unq_vs, visits)

## Transform character to factors
tbl[sapply(tbl, is.character)] <- lapply(tbl[sapply(tbl, is.character)], as.factor)

## Create a new feature: numerical age using the midpoint of each age interval
tbl$age_num <- tbl$age %>%
  gsub('\\[', '', .) %>%
  gsub('\\)', '', .) %>%
  strsplit(., split = '-') %>%
  purrr::map(.f = function(int){
    x <- as.numeric(int)
    return(mean(x))
  }) %>%
  unlist

# The following features: diag_1, diag_2, and diag_3 make
# reference of the three initial detected diagnoses. They
# have more than 700 categories. Additionally, the feature
# 'number_diagnoses' captures the sum of all of detected
# diagnoses. For that reason, diag_1,diag_2, and diag_3
# were excluded of the analysis
tbl$diag_1 <- tbl$diag_2 <- tbl$diag_3 <- NULL

# Discard expired and hospiced people from analysis
tbl$discharge_disposition_id <- tbl$discharge_disposition_id %>% as.character
tbl <- tbl %>%
  dplyr::filter(!(discharge_disposition_id %in% c('Expired','Hospice')))
tbl$discharge_disposition_id <- tbl$discharge_disposition_id %>% factor()

## Response variable
# Considering that the readmission before and after 30 days
# are both bad situations for a patient. The analysis will
# be carried out using a binary classification, merging the
# admissions before and after 30 days in one category
tbl$readmitted <- ifelse(test = tbl$readmitted %in% c('<30','>30'),
                         yes  = 1,
                         no   = 0)
# Data proportion of response category
cat(paste0('The data proportion in the response variable is as follows: \n'))
table(tbl$readmitted)/nrow(tbl)
```

## Exploratory Data Analysis

This step consists in checking the type of data and develop the final

```{r description, echo=FALSE}
summary(tbl)
```

## Correlation analysis

Explain why this

```{r modeling, echo=FALSE}
# tst <- tbl[complete.cases(tbl),] %>% base::as.data.frame()
# # cor2(df = tst)
# 
# # Numeric variables
# colnames(tbl[sapply(tbl, is.numeric)])
# tbl[sapply(tbl, is.numeric)] %>%
#   cor(use = 'pairwise.complete.obs', method = 'spearman') %>%
#   corrplot::corrplot.mixed()
# 
# # Categorical variables
# cat_vars <- tbl[sapply(tbl, is.factor)]
# cat_vars <- cat_vars[complete.cases(cat_vars),]
# cat_vars <- cat_vars %>% as.data.frame()
# p.chisq <- matrix(0, nrow = ncol(cat_vars), ncol = ncol(cat_vars), byrow = T)
# for(i in 1:ncol(cat_vars)){
#   for(j in 1:ncol(cat_vars)){
#     p.chisq[i,j] <- round(chisq.test(cat_vars[,i],cat_vars[,j])$p.value,3)
#   }
# }; rm(i); rm(j)
# 
# diag(p.chisq) <- 1
# colnames(p.chisq) <- colnames(cat_vars)
# rownames(p.chisq) <- colnames(cat_vars)
# 
# ord <- p.chisq %>%
#   corrplot::corrMatOrder(order = 'AOE')
# 
# p.chisq2 <- p.chisq[ord,ord]
# corrplot::corrplot.mixed(p.chisq2)
# 
# # Select just complete data
# tbl_cmp <- tbl[complete.cases(tbl),]
# ids     <- tbl_cmp[,1:2]
# tbl_cmp <- tbl_cmp[,-c(1:2)]
# 
# # modelr::crossv_kfold()
# train_control<- caret::trainControl(method = "cv",
#                                     number = 10,
#                                     savePredictions = TRUE)
# 
# library(doParallel)
# cl <- makePSOCKcluster(3)
# registerDoParallel(cl)
# 
# model <- caret::train(readmitted ~ ., data=tbl_cmp, trControl=train_control, method = "gbm")
# 
# stopCluster(cl)
# 
# set.seed(1235)
# inTrain <- caret::createDataPartition(y = tbl_cmp$readmitted, p = 0.7, list = FALSE)
# training <- tbl_cmp[inTrain,]
# testing  <- tbl_cmp[-inTrain,]
# 
# control_prmt <- caret::trainControl(method          = "LGOCV",
#                                     p               = 0.7,
#                                     number          = 10,
#                                     savePredictions = "final",
#                                     verboseIter     = TRUE)
# 
# model_list <- caretEnsemble::caretList(
#     readmitted ~ .,
#     data       = training,
#     trControl  = control_prmt,
#     tuneList   = list(ranger = caretModelSpec(method = "ranger", importance = "impurity")),
#     methodList = c("svmRadial", "gbm", "cforest", "hdda", "xgbTree", "xgbLinear")
#   )
```
