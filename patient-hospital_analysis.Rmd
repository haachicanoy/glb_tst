---
title: "Drivers of readmission of diabetes patients"
author: "Harold Armando Achicanoy Estrella"
date: "12/01/2020"
output: html_document
---

## Overview

The main objective of this analysis consists of identifying the variables that contribute the most to explain why some patients reconsulted after the application of diabetes treatments. The [dataset](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008#) is composed of hospital records from 130 units from the hospital network in the USA through the period 1999-2008.

Understanding the readmission process causes will help doctors to support decision making on how to address and treat diabetes patients.

To address this objective the idea is to follow a data science process applying some data preparation, description, feature selection, and finally the execution of some classification models.

The carried analysis uses the **[Spark 3.0.1](https://spark.apache.org)** general-purpose cluster computing system to run the classification models. The machine configuration is as follows: MacBook Pro (13-inch, Mid 2012), Processor: 2.5 GHz Intel Core i5, RAM: 16 GB.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# R options
options(warn = -1, scipen = 999)
if(!require(pacman)){install.packages('pacman')}
suppressMessages(library(pacman))
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
                                caret, caretEnsemble, corrplot,
                                ranger, fastcluster, sparklyr,
                                fastDummies, ape, Boruta,
                                future, future.apply, furrr,
                                lsr, RColorBrewer, DT, skimr,
                                naniar, ggrepel, DALEX,
                                breakDown, pdp, png, knitr))
```

The structure of this notebook is divided in the following sections: data obtention, data pre-processing, descriptive analysis, correlation analysis, feature selection, and classification analysis to identify the main drivers.

## 1. Data obtention

The first step consists in obtain the data from the web source, unzip the compressed file, and read it using a fast library to load text files in R.

```{r obtention, include = TRUE}
## --------------------------------------------------- ##
## Data obtention
## --------------------------------------------------- ##

if(!file.exists('./dataset_diabetes/diabetic_data.csv')){
  # Download data
  url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip'
  download.file(url, destfile = paste0(getwd(),'/dataset_diabetes.zip'))
  # Unzip files
  unzip('./dataset_diabetes.zip')
  file.remove('./dataset_diabetes.zip')
  # Load the data
  tbl <- vroom::vroom('./dataset_diabetes/diabetic_data.csv', delim = ',')
} else {
  # Load the data
  tbl <- vroom::vroom('./dataset_diabetes/diabetic_data.csv', delim = ',')
}
# Replace '?' character by NA's
tbl <- tbl %>% dplyr::na_if(y = '?')

cat(paste0('Dataset dimensions\n'))
print(dim(tbl))
```

The dataset is conformed by 101766 patients-records with 50 attributes of information.

## 2. Data pre-processing

The data pre-processing steps consist in:

* Identify and remove features without or low variance
* Replace codes by the right categories in some categorical variables
* Regroup many labels into meaningful categories
* Identify and remove features with more than 25% of missing data
* Check the data types
* Create or modify variables
* Transform categorical variables into dummy variables

```{r preprocessing, include = TRUE}
## --------------------------------------------------- ##
## Data obtention
## --------------------------------------------------- ##

if(!file.exists('./dataset_diabetes/diabetic_data.csv')){
  # Download data
  url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip'
  download.file(url, destfile = paste0(getwd(),'/dataset_diabetes.zip'))
  # Unzip files
  unzip('./dataset_diabetes.zip')
  file.remove('./dataset_diabetes.zip')
  # Load the data
  tbl <- vroom::vroom('./dataset_diabetes/diabetic_data.csv', delim = ',')
} else {
  # Load the data
  tbl <- vroom::vroom('./dataset_diabetes/diabetic_data.csv', delim = ',')
}
# Replace '?' character by NA's
tbl <- tbl %>% dplyr::na_if(y = '?')

cat(paste0('Dataset dimensions\n'))
print(dim(tbl))

## --------------------------------------------------- ##
## Data pre-processing
## --------------------------------------------------- ##
# Identify and remove variables without or with low variance
zvar <- tbl %>% caret::nzv()
cat(paste0('Removed features due to the low or null variance\n'))
print(names(tbl)[zvar])
tbl  <- tbl[,-zvar]; rm(zvar)

# Replace the codes by the right categories to the *admission* variables
# Load ID identifiers
idi  <- vroom::vroom('./dataset_diabetes/IDs_mapping.csv', delim = ',')
mtch <- which(is.na(idi$admission_type_id))
# admision_type_id
idi1 <- idi[1:(mtch[1]-1),]
# discharge_disposition_id
idi2 <- idi[(mtch[1]+1):(mtch[2]-1),]
names(idi2) <- as.character(idi2[1,])
idi2 <- idi2[-1,]
# admission_source_id
idi3 <- idi[(mtch[2]+1):nrow(idi),]
names(idi3) <- as.character(idi3[1,])
idi3 <- idi3[-1,]; rm(mtch)

tbl$admission_type_id <- factor(tbl$admission_type_id)
levels(tbl$admission_type_id) <- idi1$description
levels(tbl$admission_type_id)[levels(tbl$admission_type_id) %in% c('NULL','Not Available')] <- NA
# Create a new category which comprises the levels: 'Newborn','Trauma Center','Not Mapped'
levels(tbl$admission_type_id)[levels(tbl$admission_type_id) %in% c('Newborn','Trauma Center','Not Mapped')] <- 'Other'

tbl$discharge_disposition_id <- factor(tbl$discharge_disposition_id)
levels(tbl$discharge_disposition_id) <- idi2$description[match(levels(tbl$discharge_disposition_id), idi2$discharge_disposition_id)]
levels(tbl$discharge_disposition_id)[levels(tbl$discharge_disposition_id) %in% c('NULL','Not Available')] <- NA
# Create new categories: Discharged, Expired, Hospice, and Admitted
levels(tbl$discharge_disposition_id)[grep(pattern = '[dD][iI][sS][cC][hH][aA][rR][gG][eE][dD]', x = levels(tbl$discharge_disposition_id))] <- 'Discharged'
levels(tbl$discharge_disposition_id)[grep(pattern = '[eE][xX][pP][iI][rR][eE][dD]', x = levels(tbl$discharge_disposition_id))] <- 'Expired'
levels(tbl$discharge_disposition_id)[grep(pattern = '[hH][oO][sS][pP][iI][cC][eE]', x = levels(tbl$discharge_disposition_id))] <- 'Hospice'
levels(tbl$discharge_disposition_id)[c(2,3,5)] <- 'Admitted'

tbl$admission_source_id <- factor(tbl$admission_source_id)
levels(tbl$admission_source_id) <- idi3$description[match(levels(tbl$admission_source_id), idi3$admission_source_id)]
levels(tbl$admission_source_id)[levels(tbl$admission_source_id) %in% c('NULL','Not Available')] <- NA
# Create new categories: Transfer, Referral, and Other
levels(tbl$admission_source_id)[grep(pattern = '[tT][rR][aA][nN][sS][fF][eE][rR]', x = levels(tbl$admission_source_id))] <- 'Transfer'
levels(tbl$admission_source_id)[grep(pattern = '[rR][eE][fF][eE][rR][rR][aA][lL]', x = levels(tbl$admission_source_id))] <- 'Referral'
levels(tbl$admission_source_id)[4:8] <- 'Other'
rm(idi, idi1, idi2, idi3)

## Omit Unknown category in gender
# It only has 3 registers
cat(paste0('Omit Unknown category in gender due to low variation\n'))
print(table(tbl$gender))
tbl$gender[grep(pattern = 'Unknown', x = tbl$gender)] <- NA

## Identify variables with more than 25% of missing data
msg <- tbl %>%
  apply(X = ., MARGIN = 2, function(x){sum(is.na(x))/nrow(.)}) %>%
  sort(decreasing = T) %>%
  .[. > 0.25]
cat(paste0('Removed features due to high proportion of missing data\n'))
print(msg)

naniar::vis_miss(tbl, warn_large_data = F)

## Remove variables with more than 25% of missing data
tbl <- tbl[,-which(names(tbl) %in% names(msg))]; rm(msg)

## Create a new feature: How many times the same patient have visited the hospital?
# Select the ones with the maximum number of days interned in the hospital
visits <- tbl$patient_nbr %>% table %>% sort(decreasing = T) %>% base::as.data.frame()
names(visits)[1] <- 'patient_nbr'
visits$patient_nbr <- visits$patient_nbr %>% as.character() %>% as.numeric()
unq_vs <- visits %>% dplyr::filter(Freq == 1)
visits <- visits %>% dplyr::filter(Freq > 1)

tbl_unq <- tbl %>% dplyr::filter(patient_nbr %in% unq_vs$patient_nbr)
tbl_unq$number_visits <- 1

tbl_dup <- 1:nrow(visits) %>%
  purrr::map(.f = function(i){
    df <- tbl %>%
      dplyr::filter(patient_nbr == visits$patient_nbr[i]) %>%
      .[which.max(.$time_in_hospital)[1],]
    df$number_visits <- visits$Freq[i]
    return(df)
  }) %>%
  dplyr::bind_rows()

tbl <- rbind(tbl_dup, tbl_unq)
# Number of unique patients
cat(paste0('Unique number of patients after removing duplicated information\n'))
print(nrow(tbl))
rm(tbl_dup, tbl_unq, unq_vs, visits)

## Transform character to factors
tbl[sapply(tbl, is.character)] <- lapply(tbl[sapply(tbl, is.character)], as.factor)

## Create a new feature: numerical age using the midpoint of each age interval
tbl$age_num <- tbl$age %>%
  gsub('\\[', '', .) %>%
  gsub('\\)', '', .) %>%
  strsplit(., split = '-') %>%
  purrr::map(.f = function(int){
    x <- as.numeric(int)
    return(mean(x))
  }) %>%
  unlist

# The following features: diag_1, diag_2, and diag_3 make
# reference of the three initial detected diagnoses. They
# have more than 700 categories. Additionally, the feature
# 'number_diagnoses' captures the sum of all of detected
# diagnoses. For that reason, diag_1,diag_2, and diag_3
# were excluded of the analysis
tbl$diag_1 <- tbl$diag_2 <- tbl$diag_3 <- NULL

# Discard expired and hospiced people from analysis
tbl$discharge_disposition_id <- tbl$discharge_disposition_id %>% as.character
tbl <- tbl %>%
  dplyr::filter(!(discharge_disposition_id %in% c('Expired','Hospice')))
tbl$discharge_disposition_id <- tbl$discharge_disposition_id %>% factor()

## Response variable
# Considering that the readmission before and after 30 days
# are both bad situations for a patient. The analysis will
# be carried out using a binary classification, merging the
# admissions before and after 30 days in one category
tbl$readmitted <- ifelse(test = tbl$readmitted %in% c('<30','>30'),
                         yes  = 1,
                         no   = 0)
# Data proportion of response category
cat(paste0('Response variable proportion\n'))
print(table(tbl$readmitted)/nrow(tbl))

# Remove ID variables
tbl$encounter_id <- NULL
tbl$patient_nbr  <- NULL

# Transform categorical variables to dummies 
tbl_num <- tbl %>% fastDummies::dummy_cols(ignore_na = T)
names(tbl_num)
tbl_num <- tbl_num %>%
  dplyr::select(time_in_hospital:number_diagnoses,
                number_visits,age_num,
                race_AfricanAmerican:race_Other,
                gender_Female,gender_Male,
                admission_type_id_Emergency:admission_type_id_Other,
                discharge_disposition_id_Admitted:`discharge_disposition_id_Not Mapped`,
                admission_source_id_Referral:admission_source_id_Other,
                `A1Cresult_>7`:diabetesMed_Yes,
                readmitted)

# Based on the proportion of complete observations which is 82%
# the final decision is not impute missing data
cat('Proportion of complete observations\n')
print(nrow(tbl_num[complete.cases(tbl_num),])/nrow(tbl_num))

tbl_num_full <- tbl_num %>% tidyr::drop_na()
tbl <- tbl %>% tidyr::drop_na()

# Data proportion of response category
cat(paste0('Response variable proportion\n'))
print(table(tbl_num_full$readmitted)/nrow(tbl_num_full))

## Identify and remove categories without or with low variance
zvar <- tbl_num_full %>% caret::nzv()
cat('Dummy categories without or with low variance\n')
print(names(tbl_num_full)[zvar])
tbl_num_full <- tbl_num_full[,-zvar]; rm(zvar)

cat(paste0('Dataset dimensions\n'))
print(dim(tbl_num_full))

out_dir <- './processed_data'
if(!dir.exists(out_dir)){dir.create(out_dir, recursive = T)}

if(!file.exists(paste0(out_dir,'/diabetic_data_processed_1.csv'))){
  vroom::vroom_write(x = tbl, paste0(out_dir,'/diabetic_data_processed_1.csv'), delim = ',')
}
if(!file.exists(paste0(out_dir,'/diabetic_data_processed_2.csv'))){
  vroom::vroom_write(x = tbl_num, paste0(out_dir,'/diabetic_data_processed_2.csv'), delim = ',')
}
if(!file.exists(paste0(out_dir,'/diabetic_data_processed_2_complete.csv'))){
  vroom::vroom_write(x = tbl_num_full, paste0(out_dir,'/diabetic_data_processed_2_complete.csv'), delim = ',')
}
rm(out_dir)
```

The important highlights is this section are:

* 18 features removed due to near zero variability
* 3 features removed due to high percentage of missing data: weight (96.86% missing data), medical specialty (49.08%), and payer code (39.56%)
* Multiple records per patient are present in the dataset. That represents multiple visits to the hospital network. These records were summarized in just one per patient. Selecting the record with the maximum number of days interned in the hospital and creating a new variable called: *number_visits*
* 71518 unique patient records obtained after removing duplicate records per patient
* Age numerical variable obtained using the midpoint of the age categorical intervals
* The first three diagnoses which are categorical variables with more than 700 categories were discarded. The variable *number_diagnoses* captures the sum of all of detected diagnoses
* The people classified as Expired or in Hospice were omitted from the analysis due to they can not be readmitted
* The response variable was transformed to binary output. Considering that the readmission before and after 30 days are both bad situations for a patient. The analysis will be carried out using a binary classification, merging the readmissions before and after 30 days in one category
* The proportion of the response variables is: readmitted (35%) vs no readmitted (65%)
* All the categorical variables were transformed into dummy variables
* The percentage of complete data is: 82.7%. Considering that this is a high proportion of complete cases, missing data were not imputed
* The final dataset contains 57642 patient records with 42 features

## 3. Exploratory Data Analysis

```{r description}
## --------------------------------------------------- ##
## Exploratory Data Analysis
## --------------------------------------------------- ##

# This function brings a complete description of the dataset
# for both categorical and numerical variables
skimr::skim(tbl %>% dplyr::select(-readmitted))
tbl %>%
  dplyr::select(readmitted) %>%
  dplyr::mutate(readmitted = ifelse(readmitted == 1, 'Readmitted', 'No readmitted')) %>%
  table() %>%
  as.data.frame() %>%
  dplyr::mutate(Perc = round(Freq/sum(Freq) * 100, 2)) %>% 
  ggplot(aes_string(x = '.', y = 'Perc')) +
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  geom_text(aes(label = Perc), vjust = 1.6, color = "white", size = 3.5) +
  ylab('Percentage')
```

EDA highlights:

* In average the number of days of hospitalization is around 4
* The number of laboratory procedures, general procedures, medications, outpatient, emergency, and inpatient numbers, are positive skewed
* The number of confirmed diagnoses range between 1 and 16 with a median of 8 diagnoses
* The number of visits to the hospital network is positive skewed which means the majority of patients visits just one time. And just a few proportion visits more than once
* 75% of the patients are more than 55 years old
* The response variable has a distribution of 65% (no readmission) vs 35% (readmission)

## 4. Correlation Analysis

The correlation analysis explore the association between all of different pairs of variables in the dataset. This step is very important to discard some highly correlated features before the classification analysis.

The correlation analysis was carried out using the dataset with transformed features (dummy variables instead of the original categorical data) using the Spearman non-parametric correlation. This correlation coefficient explores monotonic (increasing or decreasing) association but not necessarily linear.

```{r corr, include = TRUE}
## --------------------------------------------------- ##
## Correlation Analysis
## --------------------------------------------------- ##

tbl_num_full <- vroom::vroom('./processed_data/diabetic_data_processed_2_complete.csv', delim = ',')

# This function approximates the correlation calculation for
# mixed variables (numerical and categorical). The following
# cases are considered:
# - Both variables numeric: non-parametric Spearman correlation
# - One variable categorical, the other one numerical: ANOVA
# test getting the R2 and applying the square root
# - Both variables categorical: Cramer's V test to measure
# association between two nominal variables
# Taken from https://gist.github.com/talegari/b514dbbc651c25e2075d88f31d48057b
source('./scripts/cor2_modified.R')

m <- cor2(df = tbl_num_full)
corrplot::corrplot(m,
                   type   = "upper",
                   method = "square",
                   order  = "hclust",
                   col    = brewer.pal(n = 8, name = "RdBu"),
                   tl.cex	= .5)
```

As can be observed in the correlation matrix there are some weak positive and negative correlations among the features in the dataset, particularly in the categories of the applied treatments.

## 5. Feature Selection

Before studying the factors that insides in the readmission condition, One important step is to identify which are the features that contributes the most to explain the response variable.

This process is done by the application of the [Boruta algorithm](https://www.jstatsoft.org/article/view/v036i11) which uses Random Forest models to quantify the importance of each predictor variable to explain the response variable. The result from this process are three category response per variable. The categories are: _Confirmed_, _Tentative_, or _Rejected_.

Despite it is not possible to apply this algorithm over the full dataset considering the machine resources a resample approach was applied. The approach followed consists in:

* Generate 20 random samples of 2000 patient observations
* Over each random sample run the Boruta algorithm
* Obtain the final decision per variable
* Using the 20 results create a frequency table getting the decision category with the maximum absolute frequency
* Select the features which have the levels: _Confirmed_ and _Tentative_

```{r fselection, include = TRUE}
## --------------------------------------------------- ##
## Feature selection
## --------------------------------------------------- ##

out_dir <- './results'
if(!dir.exists(out_dir)){dir.create(out_dir, recursive = T)}
if(!file.exists(paste0(out_dir,'/feature_selection_simulation.csv'))){
  
  # Generate a local cluster of processors
  future::plan(multiprocess, workers = future::availableCores()-1)
  # Define a seed to do the results replicable
  set.seed(1)
  # Generate 20 random seeds from a uniform distribution
  seeds <- round(runif(20) * 1000, 0)
  # Run Boruta algorithm of feature selection using 20
  # random subsets of 2000 patients information and
  # save final decision: features CONFIRMED, TENTATIVE,
  # and REJECTED
  selected_fts <- seeds %>%
    furrr::future_map(.f = function(seed){
      # Fix each seed
      set.seed(seed)
      # Obtain a random sample without replacement of 2000 observations
      smp <- sample(x = 1:nrow(tbl_num_full), size = 2000, replace = F)
      # Run Boruta algorithm of feature selection over this random sample
      fts <- Boruta::Boruta(formula = readmitted ~ ., data = tbl_num_full[smp,])
      # Get the final decision
      res <- fts$finalDecision
      return(res)
    })
  
  fts <- selected_fts %>% as.data.frame()
  fts$Feature <- rownames(fts)
  rownames(fts) <- 1:nrow(fts)
  colnames(fts)[1:20] <- paste0('Run_',1:20)
  
  write.csv(fts, paste0(out_dir,'/feature_selection_simulation.csv'), row.names = F)
} else {
  fts <- read.csv(paste0(out_dir,'/feature_selection_simulation.csv'))
}

fts %>%
  tidyr::pivot_longer(cols = Run_1:Run_20) %>%
  dplyr::group_by(Feature, value) %>%
  dplyr::summarise(Count = n()) %>%
  ggplot2::ggplot(aes(x = Feature, y = Count, fill = factor(value, levels = c('Confirmed','Tentative','Rejected')))) +
  ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
  ggplot2::geom_bar(stat = 'identity') +
  ggplot2::coord_flip() +
  ggplot2::labs(fill = 'Decision')

fnl_fst <- fts %>%
  tidyr::pivot_longer(cols = Run_1:Run_20) %>%
  dplyr::group_by(Feature, value) %>%
  dplyr::summarise(Count = n()) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(Feature) %>%
  dplyr::summarise(Decision = value[which.max(Count)]) %>%
  dplyr::filter(Decision %in% c('Confirmed','Tentative')) %>%
  dplyr::pull(Feature)
fnl_fst[1] <- gsub('\`','',fnl_fst[1])
cat('Selected features from Boruta algorithm\n')
print(fnl_fst)

tbl_num_full_sel <- tbl_num_full[,c(fnl_fst,'readmitted')]
```

Finally, 13 variables were selected and are going to be used to the classification analysis reducing the number of features and hence the model complexity.

## 6. Classification Analysis

The classification analysis was used to understand how the measured conditions affect the readmission scenario. The pipeline includes the following steps:

* Split the dataset in two partitions: training (70%) and testing (30%) data
* Over these partitions, adjust five models: a logistic regression, a artificial neural network with two hidden layers and 26 nodes each, a decision tree\* model, a random forest model with 100 trees, and a gradient boosting trees\* model
* Obtain the accuracy as a performance metric for all the models. This score allows to determine the percentage of correct classification either by readmission and not readmission conditions.
* Select the model with the best performance
* Calculate variable importance for all the features using the [moDel Agnostic Language for Exploration and eXplanation (DALEX)](https://github.com/ModelOriented/DALEX) methods
* Use the partial dependency plots as a way to understand the relation direction and to complement the variable importance
* Finally, obtain a decomposition of individual case-study predictions using [BreakDown](https://arxiv.org/abs/1804.01955) algorithm, to interpret how the best model is doing the predictions.

\* These models were fitted with default set of hyper-parameters.

```{r classification, out.width = "70%", include = T}
## --------------------------------------------------- ##
## Classification analysis
## --------------------------------------------------- ##

if(!file.exists('./results/model_accuracies.csv')){
  
  # Spark connection
  if(!exists('sc')){
    sc <- sparklyr::spark_connect(master = 'local', version = '3.0.1')
  }
  tbl_num_full_sel_spk <- sparklyr::copy_to(sc, tbl_num_full_sel, overwrite = T)
  
  # Define partitions of the dataset: 70% for training, 30% for testing
  partitions <- tbl_num_full_sel_spk %>%
    sparklyr::sdf_partition(training = 0.7, test = 0.3, seed = 1099)
  
  # Fit a logistic regression model
  fit_log <- partitions$training %>% ml_logistic_regression(readmitted ~ .)
  # Evaluate one model manually
  # prd_log <- ml_predict(fit_log, partitions$test)
  # ml_binary_classification_evaluator(x = prd_log, label_col = 'readmitted', raw_prediction_col = 'prediction')
  
  # Fit a neural network
  fit_ann <- partitions$training %>% ml_multilayer_perceptron_classifier(readmitted ~ ., layers = c(13, 26, 26, 2))
  
  # Fit a decision tree model
  fit_dct <- partitions$training %>% ml_decision_tree(readmitted ~ ., type = 'classification')
  
  # Fit a random forest model
  fit_rdf <- partitions$training %>% ml_random_forest(readmitted ~ ., type = 'classification', num_trees = 100)
  
  # Fit a gradient boosting trees model
  fit_gbt <- partitions$training %>% ml_gradient_boosted_trees(readmitted ~ ., type = 'classification')
  
  metrics <- data.frame(Model = c('Logistic regression', 'Neural network','Decision tree', 'Random forest', 'Gradient boosting trees'),
                        Training = c(ml_evaluate(fit_log, partitions$training)$accuracy(),
                                     ml_evaluate(fit_ann, partitions$training)$Accuracy,
                                     ml_evaluate(fit_dct, partitions$training)$Accuracy,
                                     ml_evaluate(fit_rdf, partitions$training)$Accuracy,
                                     ml_evaluate(fit_gbt, partitions$training)$Accuracy),
                        Testing  = c(ml_evaluate(fit_log, partitions$test)$accuracy(),
                                     ml_evaluate(fit_ann, partitions$test)$Accuracy,
                                     ml_evaluate(fit_dct, partitions$test)$Accuracy,
                                     ml_evaluate(fit_rdf, partitions$test)$Accuracy,
                                     ml_evaluate(fit_gbt, partitions$test)$Accuracy))
  write.csv(metrics, './results/model_accuracies.csv', row.names = F)
} else {
  metrics <- read.csv('./results/model_accuracies.csv')
}

metrics %>%
  tidyr::pivot_longer(cols = 2:3, names_to = 'Partition', values_to = 'Accuracy') %>%
  ggplot2::ggplot(aes(x = reorder(Model, Accuracy), y = Accuracy, fill = Partition)) +
  ggplot2::geom_bar(stat = "identity", position = position_dodge()) +
  ggplot2::scale_fill_brewer(palette = "Paired") +
  ggplot2::coord_flip() +
  ggplot2::theme_bw() +
  ggplot2::xlab('')

cat('Based on the accuracy metric the best model is the Gradient boosting trees\n')

if(FALSE){
  # Interpretation of the results
  test_set <- partitions$test %>% dplyr::collect()
  custom_predict <- function(model, new_data){
    
    new_data_spark <- copy_to(sc, new_data, name="spark_temp1b3c4e6", overwrite = T)
    spark_tbl_scored <- ml_predict(model, new_data_spark)
    res <- as.numeric(as.data.frame(spark_tbl_scored %>% select(prediction) %>% collect())$prediction)
    # dplyr::db_drop_table(con = sc, table = "spark_temp1b3c4e6")
    
    return(res)
  }
  
  # Explain
  xpl_spark_gbt <- DALEX::explain(model            = fit_gbt,
                                  data             = test_set %>% select(-readmitted),
                                  y                = test_set$readmitted,
                                  predict_function = custom_predict,
                                  label            = 'Gradient Boosting Trees model',
                                  type             = 'classification')
  
}

if(!file.exists('./results/gbt_variable_importance.png')){
  # Variable importance
  vim_spark_gbt <- DALEX::variable_importance(xpl_spark_gbt)
  plot(vim_spark_gbt)
} else {
  vimp <- './results/gbt_variable_importance.png'
  knitr::include_graphics(vimp)
}

if(!file.exists('./results/pdp_gbt.png')){
  # Predictor-response relationship
  pdp_gbt  <- DALEX::variable_effect_partial_dependency(xpl_spark_gbt,
                                                        variables = c("number_visits",
                                                                      "number_inpatient",
                                                                      "number_diagnoses",
                                                                      "time_in_hospital",
                                                                      "number_emergency",
                                                                      "age_num"))
  plot(pdp_gbt)
} else {
  pdp_m <- './results/pdp_gbt.png'
  knitr::include_graphics(pdp_m)
}

if(!(file.exists('./results/prediction_decomposition_obs1.png') &
     file.exists('./results/prediction_decomposition_obs2.png'))){
  # Prediction understanding
  row_00001 <- test_set[1,]
  row_06560 <- test_set[6560,]
  pd_spark_gbt1 <- breakDown::break_down(xpl_spark_gbt, new_observation = row_00001)
  pd_spark_gbt2 <- breakDown::break_down(xpl_spark_gbt, new_observation = row_06560)
  plot(pd_spark_gbt1)
  plot(pd_spark_gbt2)
}
```

Hightlights:

* The performance/accuracy oscillates around 0.76 of correctly classifications for the five models
* The accuracy for training and testing partitions have slight differences. This means that the models are not overfitting to the data
* Despite the accuracy differences are small among the five models. The model with the best performance is the Gradient Boosting Trees (GBT) model under default hyper-parameters, followed by decision trees and random forest models
* On the other hand, to get a better sense of the variable importance for the used features, the DALEX approach was used finding that: the number of visits, number of inpatient, time in hospital, age, number of laboratory procedures, and number of emergencies are the top 6 most contributing variables in their corresponding order.
* A Partial Dependency Plot was created for each of the top 6 variables to explore how is the relationship between the predictor variables and the probability of being readmitted or no.
  + More than one visit to the hospital and number of inpatient increases significantly the probability to be readmitted
  + While, after having more than 8 confirmed diagnoses increases linearly the probability to be readmitted
  + There is a slight increase of the probability to be readmitted between 50 and 75 years, meanwhile for the rest of the age range is almost constant
  + There is a increase of the probability to be readmitted when a patient has a number of emergencies between 0 and almost 5 times. After that it decreases
  + The number of days hospitalized shows a slightly decrease in the probability of readmission at the beginning (less than 2 days) and after that it is constant

To give a sense of how the GBT model is doing the predictions, two patients from the test partition were analyzed. 

Not readmitted patient.

```{r ptn1, out.width = "70%", include = T}
bd1 <- './results/prediction_decomposition_obs1.png'
knitr::include_graphics(bd1)
```

As can be observed is the previous plot the final prediction (final prognosis) for this patient is 0, but this is a composition of positive and negative impacts from the attributes values. For instance, this patient visited the hospital just once and never was inpatient. Those two values have a negative impact in the probability to be readmitted, so those decreases the base line value (intercept) from 0.224 to 0.

Readmitted patient

```{r ptn2, out.width = "70%", include = T}
bd2 <- './results/prediction_decomposition_obs2.png'
knitr::include_graphics(bd2)
```

On the contrary, a patient which is readmitted the model also predict it well. And basically, the only variable that is influencing positively the final prediction is the number of visits (this patient had 14 visits to hospital network).

```{r closespark, include = T}
if(exists('sc')){
  spark_disconnect(sc) 
}
```

## Conclusions

* The drivers of the readmission of diabetes patients were analyzed by a data science process.
* The number of visits, number of inpatient, and the number of confirmed diagnoses are the main drivers that increases the probability to be readmitted
* Further analysis can consider:
  + Impute missing data to include the 100% of the data
  + Optimization of the hyper-parameters for the classification models using cross-validation to improve the classification performance
