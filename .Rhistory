dplyr::pull(Feature)
fnl_fst <- fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
dplyr::ungroup() %>%
dplyr::group_by(Feature) %>%
dplyr::summarise(Decision = value[which.max(Count)]) %>%
dplyr::filter(Decision %in% c('Confirmed','Tentative')) %>%
dplyr::pull(Feature)
fnl_fst
tbl_num_sel_bin <- tbl_num_full_bin[,c(fnl_fst,'readmitted')]
fnl_fst[1]
gsub('`\\','',fnl_fst[1])
gsub('\`','',fnl_fst[1])
fnl_fst[1] <- gsub('\`','',fnl_fst[1])
tbl_num_sel_bin <- tbl_num_full_bin[,c(fnl_fst,'readmitted')]
tbl_fnl_spk <- sparklyr::copy_to(sc, tbl_num_sel_bin, overwrite = T)
sc <- sparklyr::spark_connect(master = 'local')
tbl_fnl_spk <- sparklyr::copy_to(sc, tbl_num_sel_bin, overwrite = T)
partitions2 <- tbl_fnl_spk %>%
sparklyr::sdf_partition(training = 0.7, test = 0.3, seed = 1099)
# Fit a linear model to the training dataset selected features
fit2 <- partitions2$training %>%
ml_logistic_regression(readmitted ~ .)
pred2 <- ml_predict(fit2, partitions2$test)
ml_binary_classification_eval(pred2)
fit2
fit2$coefficients
fit2$coefficients %>% plot()
# Fit a linear model to the training dataset selected features
fit2 <- partitions2$training %>%
dplyr::select(-number_visits) %>%
ml_logistic_regression(readmitted ~ .)
fit2$coefficients
fit2$coefficients %>% sort(decreasing = T)
?ml_gradient_boosted_trees
# Fit a GBM model to the training dataset selected features
gbm_fit <- partitions2$training %>%
sparklyr::ml_gradient_boosted_trees(readmitted ~ .)
pred3 <- ml_predict(gbm_fit, partitions2$test)
ml_binary_classification_eval(pred3)
pred3
ml_binary_classification_evaluator(pred3)
?ml_binary_classification_eval
pred3
ml_binary_classification_eval(pred3, raw_prediction_col = 'prediction')
ml_binary_classification_eval(pred3, raw_prediction_col = "prediction")
ml_binary_classification_eval(pred3, prediction_col = "prediction")
ml_binary_classification_eval(pred3, label_col = 'readmitted', prediction_col = "prediction")
ml_binary_classification_eval(x = pred3, label_col = 'readmitted', prediction_col = "prediction")
ml_binary_classification_evaluator(x = pred3, label_col = 'readmitted', raw_prediction_col = 'prediction')
ml_binary_classification_evaluator(x = pred2, label_col = 'readmitted', raw_prediction_col = 'prediction')
gbm_fit
options(warn = -1, scipen = 999)
if(!require(pacman)){install.packages('pacman')}
suppressMessages(library(pacman))
suppressMessages(pacman::p_load(tidyverse, vroom, psych, caret, caretEnsemble, corrplot, ranger, fastcluster, sparklyr, fastDummies, ape, Boruta, future, future.apply, furrr))
## Obtain the data
if(!file.exists(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'))){
## Download data
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip'
download.file(url, destfile = paste0(getwd(),'/dataset_diabetes.zip'))
## Unzip files
unzip(paste0(getwd(),'/dataset_diabetes.zip'))
file.remove(paste0(getwd(),'/dataset_diabetes.zip'))
## Load the data
tbl <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'), delim = ',')
} else {
## Load the data
tbl <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'), delim = ',')
}
## Replace '?' character by NA's
tbl <- tbl %>% dplyr::na_if(y = '?')
## --------------------------------------------------- ##
## Data pre-processing
## --------------------------------------------------- ##
## Identify and remove variables without or with low variance
zvar <- tbl %>% caret::nzv()
tbl  <- tbl[,-zvar]
rm(zvar)
idi  <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/IDs_mapping.csv'), delim = ',')
mtch <- which(is.na(idi$admission_type_id))
# admision_type_id
idi1 <- idi[1:(mtch[1]-1),]
# discharge_disposition_id
idi2 <- idi[(mtch[1]+1):(mtch[2]-1),]
names(idi2) <- as.character(idi2[1,])
idi2 <- idi2[-1,]
# admission_source_id
idi3 <- idi[(mtch[2]+1):nrow(idi),]
names(idi3) <- as.character(idi3[1,])
idi3 <- idi3[-1,]
tbl$admission_type_id <- factor(tbl$admission_type_id)
levels(tbl$admission_type_id) <- idi1$description
levels(tbl$admission_type_id)[levels(tbl$admission_type_id) %in% c('NULL','Not Available')] <- NA
# Create a new category which comprises the levels: 'Newborn','Trauma Center','Not Mapped'
levels(tbl$admission_type_id)[levels(tbl$admission_type_id) %in% c('Newborn','Trauma Center','Not Mapped')] <- 'Other'
tbl$discharge_disposition_id <- factor(tbl$discharge_disposition_id)
levels(tbl$discharge_disposition_id) <- idi2$description[match(levels(tbl$discharge_disposition_id), idi2$discharge_disposition_id)]
levels(tbl$discharge_disposition_id)[levels(tbl$discharge_disposition_id) %in% c('NULL','Not Available')] <- NA
levels(tbl$discharge_disposition_id)[grep(pattern = '[dD][iI][sS][cC][hH][aA][rR][gG][eE][dD]', x = levels(tbl$discharge_disposition_id))] <- 'Discharged'
levels(tbl$discharge_disposition_id)[grep(pattern = '[eE][xX][pP][iI][rR][eE][dD]', x = levels(tbl$discharge_disposition_id))] <- 'Expired'
levels(tbl$discharge_disposition_id)[grep(pattern = '[hH][oO][sS][pP][iI][cC][eE]', x = levels(tbl$discharge_disposition_id))] <- 'Hospice'
levels(tbl$discharge_disposition_id)[c(2,3,5)] <- 'Admitted'
tbl$admission_source_id <- factor(tbl$admission_source_id)
levels(tbl$admission_source_id) <- idi3$description[match(levels(tbl$admission_source_id), idi3$admission_source_id)]
levels(tbl$admission_source_id)[levels(tbl$admission_source_id) %in% c('NULL','Not Available')] <- NA
levels(tbl$admission_source_id)[grep(pattern = '[tT][rR][aA][nN][sS][fF][eE][rR]', x = levels(tbl$admission_source_id))] <- 'Transfer'
levels(tbl$admission_source_id)[grep(pattern = '[rR][eE][fF][eE][rR][rR][aA][lL]', x = levels(tbl$admission_source_id))] <- 'Referral'
levels(tbl$admission_source_id)[4:8] <- 'Other'
rm(idi, idi1, idi2, idi3)
tbl$gender[grep(pattern = 'Unknown', x = tbl$gender)] <- NA
## Identify variables with more than 15% of missing data
msg <- tbl %>%
apply(X = ., MARGIN = 2, function(x){sum(is.na(x))/nrow(.)}) %>%
sort(decreasing = T) %>%
.[. > 0.15]
print(msg)
# Remove variables with more than 15% of missing data
tbl <- tbl[,-which(names(tbl) %in% names(msg))]
visits <- tbl$patient_nbr %>% table %>% sort(decreasing = T) %>% base::as.data.frame()
names(visits)[1] <- 'patient_nbr'
visits$patient_nbr <- visits$patient_nbr %>% as.character() %>% as.numeric()
unq_vs <- visits %>% dplyr::filter(Freq == 1)
visits <- visits %>% dplyr::filter(Freq > 1)
tbl_unq <- tbl %>% dplyr::filter(patient_nbr %in% unq_vs$patient_nbr)
tbl_unq$number_visits <- 1
tbl_dup <- 1:nrow(visits) %>%
purrr::map(.f = function(i){
df <- tbl %>%
dplyr::filter(patient_nbr == visits$patient_nbr[i]) %>%
.[which.max(.$time_in_hospital)[1],]
df$number_visits <- visits$Freq[i]
return(df)
}) %>%
dplyr::bind_rows()
tbl <- rbind(tbl_dup, tbl_unq)
rm(tbl_dup, tbl_unq, unq_vs, visits)
rm(msg)
rm(mtch)
print(nrow(tbl))
## Transform character to factors
tbl[sapply(tbl, is.character)] <- lapply(tbl[sapply(tbl, is.character)], as.factor)
## Create a new feature: numerical age using the midpoint of each age interval
tbl$age_num <- tbl$age %>%
gsub('\\[', '', .) %>%
gsub('\\)', '', .) %>%
strsplit(., split = '-') %>%
purrr::map(.f = function(int){
x <- as.numeric(int)
return(mean(x))
}) %>%
unlist
## Response variable
# Considering that the readmission before and after 30 days
# are both bad situations for a patient. The analysis will
# be carried out using a binary classification, merging the
# admissions before and after 30 days in one category
tbl$readmitted <- ifelse(test = tbl$readmitted %in% c('<30','>30'),
yes  = 1,
no   = 0)
table(tbl$readmitted)
# Data proportion of response category
table(tbl$readmitted)/nrow(tbl)
names(tbl)
View(tbl)
# The following features: diag_1, diag_2, and diag_3 make
# reference of the three initial detected diagnoses. They
# have more than 700 categories. Additionally, the feature
# 'number_diagnoses' captures the sum of all of detected
# diagnoses. For that reason, diag_1,diag_2, and diag_3
# were excluded of the analysis
tbl$diag_1 <- tbl$diag_2 <- tbl$diag_3 <- NULL
# Discard expired and hospiced people from analysis
tbl$discharge_disposition_id <- tbl$discharge_disposition_id %>% as.character
tbl <- tbl %>%
dplyr::filter(!(discharge_disposition_id %in% c('Expired','Hospice')))
# Data proportion of response category
table(tbl$readmitted)/nrow(tbl)
# Data proportion of response category
table(tbl$readmitted)/nrow(tbl)
summary(tbl)
# Remove ID variables
tbl$encounter_id <- NULL
tbl$patient_nbr  <- NULL
# Quick summary of the data
summary(tbl)
# Transform categorical variables to dummies
tbl_num <- tbl %>% fastDummies::dummy_cols(ignore_na = T)
names(tbl_num)
tbl_num <- tbl_num %>%
dplyr::select(time_in_hospital:number_diagnoses,
number_visits,age_num,
race_AfricanAmerican:race_Other,
gender_Female,gender_Male,
admission_type_id_Emergency:admission_type_id_Other,
discharge_disposition_id_Admitted:`discharge_disposition_id_Not Mapped`,
admission_source_id_Referral:admission_source_id_Other,
`A1Cresult_>7`:diabetesMed_Yes,
readmitted)
# Proportion of complete observations
nrow(tbl_num[complete.cases(tbl_num),])/nrow(tbl_num)
tbl_num_full <- tbl_num %>% tidyr::drop_na()
# Data proportion of response category
table(tbl_num_full$readmitted)/nrow(tbl_num_full)
View(tbl_num_full)
## Identify and remove variables without or with low variance
zvar <- tbl_num_full %>% caret::nzv()
zvar
tbl_num_full <- tbl_num_full[,-zvar]; rm(zvar)
View(tbl_num_full)
getwd()
paste0(getwd(),'/processed')
out_dir <- paste0(getwd(),'/processed_data')
if(!dir.exists(out_dir)){dir.create(out_dir, recursive = T)}
vroom::vroom_write(x = tbl, paste0(out_dir,'/diabetic_data_processed_1.csv'), delim = ',')
vroom::vroom_write(x = tbl_num, paste0(out_dir,'/diabetic_data_processed_2.csv'), delim = ',')
vroom::vroom_write(x = tbl_num_full, paste0(out_dir,'/diabetic_data_processed_2_complete.csv'), delim = ',')
## Feature importance
future::plan(multiprocess, workers = future::availableCores()-1)
set.seed(1)
seeds <- round(runif(20) * 1000, 0)
selected_fts <- seeds %>%
furrr::future_map(.f = function(seed){
set.seed(seed)
smp <- sample(x = 1:nrow(tbl_num_full), size = 2000, replace = F)
fts <- Boruta::Boruta(formula = readmitted ~ ., data = tbl_num_full[smp,])
res <- fts$finalDecision
return(res)
})
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
caret, caretEnsemble, corrplot,
ranger, fastcluster, sparklyr,
fastDummies, ape, Boruta,
future, future.apply, furrr,
cor2))
fts <- selected_fts %>% as.data.frame()
fts$Feature <- rownames(fts)
rownames(fts) <- 1:nrow(fts)
colnames(fts)[1:20] <- paste0('Run_',1:20)
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = reorder(Feature, -Count), y = Count, fill = value)) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = reorder(Feature, -Count), y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1') +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = reorder(Feature, -Count), y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
fnl_fst <- fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
dplyr::ungroup() %>%
dplyr::group_by(Feature) %>%
dplyr::summarise(Decision = value[which.max(Count)]) %>%
dplyr::filter(Decision %in% c('Confirmed','Tentative')) %>%
dplyr::pull(Feature)
fnl_fst[1] <- gsub('\`','',fnl_fst[1])
fnl_fst
rm(out_dir)
library(cor2)
install.packages("cor2")
library(lsr)
install.packages('lsr')
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
caret, caretEnsemble, corrplot,
ranger, fastcluster, sparklyr,
fastDummies, ape, Boruta,
future, future.apply, furrr,
lsr))
cor2 <- function(df){
stopifnot(inherits(df, "data.frame"))
stopifnot(sapply(df, class) %in% c("integer"
, "numeric"
, "factor"
, "character"))
cor_fun <- function(pos_1, pos_2){
# both are numeric
if(class(df[[pos_1]]) %in% c("integer", "numeric") &&
class(df[[pos_2]]) %in% c("integer", "numeric")){
r <- stats::cor(df[[pos_1]], df[[pos_2]], method = 'spearman', use = "pairwise.complete.obs")
}
# one is numeric and other is a factor/character
if(class(df[[pos_1]]) %in% c("integer", "numeric") &&
class(df[[pos_2]]) %in% c("factor", "character")){
r <- sqrt(summary(stats::lm(df[[pos_1]] ~ as.factor(df[[pos_2]])))[["r.squared"]])
}
if(class(df[[pos_2]]) %in% c("integer", "numeric") &&
class(df[[pos_1]]) %in% c("factor", "character")){
r <- sqrt(summary(stats::lm(df[[pos_2]] ~ as.factor(df[[pos_1]])))[["r.squared"]])
}
# both are factor/character
if(class(df[[pos_1]]) %in% c("factor", "character") &&
class(df[[pos_2]]) %in% c("factor", "character")){
r <- lsr::cramersV(df[[pos_1]], df[[pos_2]], simulate.p.value = TRUE)
}
return(r)
}
cor_fun <- Vectorize(cor_fun)
# now compute corr matrix
corrmat <- outer(1:ncol(df), 1:ncol(df), function(x, y) cor_fun(x, y))
rownames(corrmat) <- colnames(df)
colnames(corrmat) <- colnames(df)
return(corrmat)
}
m <- cor2(df = tbl_num_full)
m[1:5,1:5]
m %>%
corrplot::corrplot.mixed()
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
caret, caretEnsemble, corrplot,
ranger, fastcluster, sparklyr,
fastDummies, ape, Boruta,
future, future.apply, furrr,
lsr, RColorBrewer))
corrplot::corrplot(m,
type  = "upper",
order = "hclust",
col   = brewer.pal(n = 8, name = "RdBu"))
?corrplot
corrplot::corrplot(m,
type  = "upper",
order = "hclust",
col   = brewer.pal(n = 8, name = "RdBu"),
tl.cex	= 1)
corrplot::corrplot(m,
type  = "upper",
order = "hclust",
col   = brewer.pal(n = 8, name = "RdBu"),
tl.cex	= .2)
corrplot::corrplot(m,
type  = "upper",
order = "hclust",
col   = brewer.pal(n = 8, name = "RdBu"),
tl.cex	= .5)
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
caret, caretEnsemble, corrplot,
ranger, fastcluster, sparklyr,
fastDummies, ape, Boruta,
future, future.apply, furrr,
lsr, RColorBrewer, DT))
glimpse(tbl)
glimpse(tbl) %>% tidy()
str(tbl)
psych::describe(tbl)
DT::datatable(psych::describe(tbl))
?pivot_longer
str(tbl)
apply(tbl, 2, class)
tbl$age_num %>% class()
lapply(tbl, class)
lapply(tbl, class) %>% unlist()
cls_vr <- lapply(tbl, class) %>% unlist()
cat_vr <- names(cls_vr)[which(cls_vr == 'factor')]
cat_vr
num_vr <- names(cls_vr)[which(cls_vr == 'numeric')]
num_vr
fqTable <- tbl[,cat_vr] %>%
tidyr::pivot_longer(names_to = 'measure', values_to = 'value') %>%
dplyr::count(measure, value)
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
caret, caretEnsemble, corrplot,
ranger, fastcluster, sparklyr,
fastDummies, ape, Boruta,
future, future.apply, furrr,
lsr, RColorBrewer, DT, skimr))
skimr::skim(tbl)
# Taken from https://gist.github.com/talegari/b514dbbc651c25e2075d88f31d48057b
source(paste0(getwd(),'/scripts/cor2_modified.R'))
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
# dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = reorder(Feature, -Count), y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
# dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = reorder(Feature, -Feature), y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
# dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = reorder(Feature, Feature), y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
# dplyr::filter(!(value == 'Rejected' & Count == 20)) %>%
ggplot2::ggplot(aes(x = Feature, y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip()
out_dir <- paste0(getwd(),'/results')
if(!dir.exists(out_dir)){dir.create(out_dir, recursive = T)}
corrplot::corrplot(m,
type  = "upper",
order = "hclust",
col   = brewer.pal(n = 8, name = "RdBu"),
tl.cex	= .5)
knitr::opts_chunk$set(echo = TRUE)
# R options
options(warn = -1, scipen = 999)
if(!require(pacman)){install.packages('pacman')}
suppressMessages(library(pacman))
suppressMessages(pacman::p_load(tidyverse, vroom, psych, caret, corrplot, fastcluster, sparklyr))
cat(paste0('Dataset dimension\n'))
print(dim(tbl))
---
title: "The main drivers of readmission of diabetes patients"
author: "Harold Armando Achicanoy Estrella"
date: "12/01/2020"
output: html_document
---
## Overview
The main objective of this analysis consists of identifying the variables that contribute the most to explain why some patients reconsulted after the application of diabetes treatments. The [dataset](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008#) is composed of hospital records from 130 units from the hospital network in the USA through the period 1999-2008.
Understanding the readmission process causes will help doctors to support decision making on how to address and treat diabetes patients.
To address this objective the idea is to follow a data science process applying some data preparation, description, feature selection, and finally the execution of some classification models. Put some highlighted results.
The carried analysis uses the **Spark 2.1.0** framework to run the Machine Learning models. The machine configuration is as follows: MacBook Pro (13-inch, Mid 2012), Processor: 2.5 GHz Intel Core i5, RAM: 16 GB.
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# R options
options(warn = -1, scipen = 999)
if(!require(pacman)){install.packages('pacman')}
suppressMessages(library(pacman))
suppressMessages(pacman::p_load(tidyverse, vroom, psych,
caret, caretEnsemble, corrplot,
ranger, fastcluster, sparklyr,
fastDummies, ape, Boruta,
future, future.apply, furrr,
lsr, RColorBrewer, DT, skimr))
```
The structure of this notebook is divided in the following sections: data obtention, data pre-processing, descriptive analysis, correlation analysis, feature selection, and models fitting to identify the main drivers.
## 1. Data obtention
The first step consists in obtain the data from the web source, unzip the compressed file, and read it using a fast library to load text files in R.
```{r, include = TRUE}
## --------------------------------------------------- ##
## Data obtention
## --------------------------------------------------- ##
if(!file.exists(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'))){
## Download data
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip'
download.file(url, destfile = paste0(getwd(),'/dataset_diabetes.zip'))
## Unzip files
unzip(paste0(getwd(),'/dataset_diabetes.zip'))
file.remove(paste0(getwd(),'/dataset_diabetes.zip'))
## Load the data
tbl <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'), delim = ',')
} else {
## Load the data
tbl <- vroom::vroom(paste0(getwd(),'/dataset_diabetes/diabetic_data.csv'), delim = ',')
}
## Replace '?' character by NA's
tbl <- tbl %>% dplyr::na_if(y = '?')
```
The dataset is conformed by 101766 patients-records with 50 attributes of information.
```{r dimension, include = TRUE}
cat(paste0('Dataset dimensions\n'))
print(dim(tbl))
```
## Data pre-processing
The data pre-processing steps consist in:
* Identify and remove features without or low variance
* Replace codes by the right categories in some categorical variables
* Regroup many labels into meaningful categories
* Identify and remove features with more than 25% of missing data
* Check the data types
* Create or modify variables
fts
out_dir
write.csv(fts, paste0(out_dir,'/feature_selection_simulation.csv'), row.names = F)
fts %>%
tidyr::pivot_longer(cols = Run_1:Run_20) %>%
dplyr::group_by(Feature, value) %>%
dplyr::summarise(Count = n()) %>%
ggplot2::ggplot(aes(x = Feature, y = Count, fill = value)) +
ggplot2::scale_fill_brewer(palette = 'Set1', direction = -1) +
ggplot2::geom_bar(stat = 'identity') +
ggplot2::coord_flip() +
ggplot2::labs(fill = 'Decision')
?corrplot
