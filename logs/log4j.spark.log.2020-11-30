20/11/30 23:05:51 INFO SparkContext: Running Spark version 2.1.0
20/11/30 23:05:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/11/30 23:05:52 INFO SecurityManager: Changing view acls to: macbook
20/11/30 23:05:52 INFO SecurityManager: Changing modify acls to: macbook
20/11/30 23:05:52 INFO SecurityManager: Changing view acls groups to: 
20/11/30 23:05:52 INFO SecurityManager: Changing modify acls groups to: 
20/11/30 23:05:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(macbook); groups with view permissions: Set(); users  with modify permissions: Set(macbook); groups with modify permissions: Set()
20/11/30 23:05:52 INFO Utils: Successfully started service 'sparkDriver' on port 52717.
20/11/30 23:05:52 INFO SparkEnv: Registering MapOutputTracker
20/11/30 23:05:52 INFO SparkEnv: Registering BlockManagerMaster
20/11/30 23:05:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/11/30 23:05:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/11/30 23:05:52 INFO DiskBlockManager: Created local directory at /private/var/folders/kf/_5bjnbzx49n7xxn3jz9qp8f00000gn/T/blockmgr-2f0ddca1-d0a5-437f-8198-5c9bebb76e94
20/11/30 23:05:52 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
20/11/30 23:05:52 INFO SparkEnv: Registering OutputCommitCoordinator
20/11/30 23:05:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/11/30 23:05:52 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/11/30 23:05:53 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:52717/jars/sparklyr-2.0-2.11.jar with timestamp 1606795553025
20/11/30 23:05:53 INFO Executor: Starting executor ID driver on host localhost
20/11/30 23:05:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52718.
20/11/30 23:05:53 INFO NettyBlockTransferService: Server created on 127.0.0.1:52718
20/11/30 23:05:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/11/30 23:05:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52718, None)
20/11/30 23:05:53 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52718 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 52718, None)
20/11/30 23:05:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52718, None)
20/11/30 23:05:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52718, None)
20/11/30 23:05:53 INFO SharedState: Warehouse path is 'file:/Volumes/BACKUP/Scripts/R/glb_tst/spark-warehouse'.
20/11/30 23:05:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
20/11/30 23:05:54 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
20/11/30 23:05:59 INFO ObjectStore: ObjectStore, initialize called
20/11/30 23:06:00 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
20/11/30 23:06:00 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
20/11/30 23:06:02 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
20/11/30 23:06:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
20/11/30 23:06:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
20/11/30 23:06:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
20/11/30 23:06:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
20/11/30 23:06:04 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/11/30 23:06:04 INFO ObjectStore: Initialized ObjectStore
20/11/30 23:06:05 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
20/11/30 23:06:05 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
20/11/30 23:06:05 INFO HiveMetaStore: Added admin role in metastore
20/11/30 23:06:05 INFO HiveMetaStore: Added public role in metastore
20/11/30 23:06:05 INFO HiveMetaStore: No user is added in admin role, since config is empty
20/11/30 23:06:06 INFO HiveMetaStore: 0: get_all_databases
20/11/30 23:06:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_all_databases	
20/11/30 23:06:06 INFO HiveMetaStore: 0: get_functions: db=default pat=*
20/11/30 23:06:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
20/11/30 23:06:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
20/11/30 23:06:06 INFO SessionState: Created HDFS directory: /tmp/hive/macbook
20/11/30 23:06:06 INFO SessionState: Created local directory: /var/folders/kf/_5bjnbzx49n7xxn3jz9qp8f00000gn/T/macbook
20/11/30 23:06:06 INFO SessionState: Created local directory: /var/folders/kf/_5bjnbzx49n7xxn3jz9qp8f00000gn/T/62889ad4-2034-469d-8398-7f05cabaab47_resources
20/11/30 23:06:06 INFO SessionState: Created HDFS directory: /tmp/hive/macbook/62889ad4-2034-469d-8398-7f05cabaab47
20/11/30 23:06:06 INFO SessionState: Created local directory: /var/folders/kf/_5bjnbzx49n7xxn3jz9qp8f00000gn/T/macbook/62889ad4-2034-469d-8398-7f05cabaab47
20/11/30 23:06:06 INFO SessionState: Created HDFS directory: /tmp/hive/macbook/62889ad4-2034-469d-8398-7f05cabaab47/_tmp_space.db
20/11/30 23:06:06 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Volumes/BACKUP/Scripts/R/glb_tst/spark-warehouse
20/11/30 23:06:06 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:06 INFO HiveMetaStore: 0: get_database: global_temp
20/11/30 23:06:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: global_temp	
20/11/30 23:06:06 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
20/11/30 23:06:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:06:10 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:10 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:10 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:10 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:06:10 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:06:11 INFO CodeGenerator: Code generated in 433.302351 ms
20/11/30 23:06:11 INFO CodeGenerator: Code generated in 15.847763 ms
20/11/30 23:06:11 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:06:11 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:116)
20/11/30 23:06:11 INFO DAGScheduler: Got job 0 (count at utils.scala:116) with 1 output partitions
20/11/30 23:06:11 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:116)
20/11/30 23:06:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/11/30 23:06:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
20/11/30 23:06:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:116), which has no missing parents
20/11/30 23:06:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
20/11/30 23:06:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 912.3 MB)
20/11/30 23:06:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 912.3 MB)
20/11/30 23:06:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
20/11/30 23:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:116)
20/11/30 23:06:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/11/30 23:06:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6060 bytes)
20/11/30 23:06:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/11/30 23:06:12 INFO ContextCleaner: Cleaned accumulator 0
20/11/30 23:06:12 INFO Executor: Fetching spark://127.0.0.1:52717/jars/sparklyr-2.0-2.11.jar with timestamp 1606795553025
20/11/30 23:06:12 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52717 after 26 ms (0 ms spent in bootstraps)
20/11/30 23:06:12 INFO Utils: Fetching spark://127.0.0.1:52717/jars/sparklyr-2.0-2.11.jar to /private/var/folders/kf/_5bjnbzx49n7xxn3jz9qp8f00000gn/T/spark-fea63591-d1e6-4765-92f0-f34a0ce35762/userFiles-940b7b85-b335-4e7d-b2ef-049ef055f4eb/fetchFileTemp794520577901856970.tmp
20/11/30 23:06:12 INFO Executor: Adding file:/private/var/folders/kf/_5bjnbzx49n7xxn3jz9qp8f00000gn/T/spark-fea63591-d1e6-4765-92f0-f34a0ce35762/userFiles-940b7b85-b335-4e7d-b2ef-049ef055f4eb/sparklyr-2.0-2.11.jar to class loader
20/11/30 23:06:12 INFO CodeGenerator: Code generated in 22.522306 ms
20/11/30 23:06:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1893 bytes result sent to driver
20/11/30 23:06:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 422 ms on localhost (executor driver) (1/1)
20/11/30 23:06:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/11/30 23:06:12 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:116) finished in 0.453 s
20/11/30 23:06:12 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:06:12 INFO DAGScheduler: running: Set()
20/11/30 23:06:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
20/11/30 23:06:12 INFO DAGScheduler: failed: Set()
20/11/30 23:06:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:116), which has no missing parents
20/11/30 23:06:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
20/11/30 23:06:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.3 MB)
20/11/30 23:06:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 912.3 MB)
20/11/30 23:06:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
20/11/30 23:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:116)
20/11/30 23:06:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/11/30 23:06:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 5945 bytes)
20/11/30 23:06:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/11/30 23:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
20/11/30 23:06:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2035 bytes result sent to driver
20/11/30 23:06:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 60 ms on localhost (executor driver) (1/1)
20/11/30 23:06:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/11/30 23:06:12 INFO DAGScheduler: ResultStage 1 (count at utils.scala:116) finished in 0.062 s
20/11/30 23:06:12 INFO DAGScheduler: Job 0 finished: count at utils.scala:116, took 0.834115 s
20/11/30 23:06:12 INFO CodeGenerator: Code generated in 11.883777 ms
20/11/30 23:06:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:06:14 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:14 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:14 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:14 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:06:14 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:06:14 INFO CodeGenerator: Code generated in 10.022609 ms
20/11/30 23:06:14 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:06:14 INFO DAGScheduler: Got job 1 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:06:14 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:46)
20/11/30 23:06:14 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:06:14 INFO DAGScheduler: Missing parents: List()
20/11/30 23:06:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at map at utils.scala:43), which has no missing parents
20/11/30 23:06:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 912.3 MB)
20/11/30 23:06:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.6 KB, free 912.3 MB)
20/11/30 23:06:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 912.3 MB)
20/11/30 23:06:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
20/11/30 23:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at map at utils.scala:43)
20/11/30 23:06:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/11/30 23:06:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
20/11/30 23:06:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/11/30 23:06:14 INFO CodeGenerator: Code generated in 11.771932 ms
20/11/30 23:06:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1231 bytes result sent to driver
20/11/30 23:06:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (executor driver) (1/1)
20/11/30 23:06:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/11/30 23:06:14 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:46) finished in 0.036 s
20/11/30 23:06:14 INFO DAGScheduler: Job 1 finished: collect at utils.scala:46, took 0.045807 s
20/11/30 23:06:17 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 912.3 MB)
20/11/30 23:06:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 912.3 MB)
20/11/30 23:06:17 INFO ContextCleaner: Cleaned shuffle 0
20/11/30 23:06:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 912.3 MB)
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 110
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 109
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 12
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 11
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 10
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 9
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 8
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 7
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 6
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 5
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 4
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 3
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 2
20/11/30 23:06:17 INFO ContextCleaner: Cleaned accumulator 1
20/11/30 23:06:19 INFO SparkSqlParser: Parsing command: tbl_num_full
20/11/30 23:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full` AS `q01`
WHERE (0 = 1)
20/11/30 23:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full`
20/11/30 23:06:19 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
20/11/30 23:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full` AS `q01`
WHERE (0 = 1)
20/11/30 23:06:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:06:20 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:20 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:20 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:06:20 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:06:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:06:20 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:06:20 INFO CodeGenerator: Code generated in 20.998877 ms
20/11/30 23:06:20 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:06:20 INFO DAGScheduler: Registering RDD 20 (count at utils.scala:116)
20/11/30 23:06:20 INFO DAGScheduler: Got job 2 (count at utils.scala:116) with 1 output partitions
20/11/30 23:06:20 INFO DAGScheduler: Final stage: ResultStage 4 (count at utils.scala:116)
20/11/30 23:06:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/11/30 23:06:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/11/30 23:06:20 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at utils.scala:116), which has no missing parents
20/11/30 23:06:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
20/11/30 23:06:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.7 KB, free 912.3 MB)
20/11/30 23:06:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52718 (size: 4.7 KB, free: 912.3 MB)
20/11/30 23:06:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
20/11/30 23:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at utils.scala:116)
20/11/30 23:06:20 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/11/30 23:06:20 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6379 bytes)
20/11/30 23:06:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/11/30 23:06:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1806 bytes result sent to driver
20/11/30 23:06:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (executor driver) (1/1)
20/11/30 23:06:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/11/30 23:06:20 INFO DAGScheduler: ShuffleMapStage 3 (count at utils.scala:116) finished in 0.023 s
20/11/30 23:06:20 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:06:20 INFO DAGScheduler: running: Set()
20/11/30 23:06:20 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/11/30 23:06:20 INFO DAGScheduler: failed: Set()
20/11/30 23:06:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at count at utils.scala:116), which has no missing parents
20/11/30 23:06:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
20/11/30 23:06:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.3 MB)
20/11/30 23:06:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 912.3 MB)
20/11/30 23:06:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
20/11/30 23:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at count at utils.scala:116)
20/11/30 23:06:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/11/30 23:06:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
20/11/30 23:06:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/11/30 23:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/30 23:06:20 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
20/11/30 23:06:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 13 ms on localhost (executor driver) (1/1)
20/11/30 23:06:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/11/30 23:06:20 INFO DAGScheduler: ResultStage 4 (count at utils.scala:116) finished in 0.014 s
20/11/30 23:06:20 INFO DAGScheduler: Job 2 finished: count at utils.scala:116, took 0.061704 s
20/11/30 23:07:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:07:07 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:07:07 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:07:07 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:07:07 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:07:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:07:07 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:07:07 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:07:07 INFO DAGScheduler: Got job 3 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:07:07 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:46)
20/11/30 23:07:07 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:07:07 INFO DAGScheduler: Missing parents: List()
20/11/30 23:07:07 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:43), which has no missing parents
20/11/30 23:07:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 912.3 MB)
20/11/30 23:07:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 912.3 MB)
20/11/30 23:07:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 912.3 MB)
20/11/30 23:07:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
20/11/30 23:07:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:43)
20/11/30 23:07:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/11/30 23:07:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6361 bytes)
20/11/30 23:07:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/11/30 23:07:07 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1246 bytes result sent to driver
20/11/30 23:07:07 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 15 ms on localhost (executor driver) (1/1)
20/11/30 23:07:07 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/11/30 23:07:07 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:46) finished in 0.016 s
20/11/30 23:07:07 INFO DAGScheduler: Job 3 finished: collect at utils.scala:46, took 0.030314 s
20/11/30 23:07:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full`
20/11/30 23:07:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4ba0e765_96f1_4d5a_8937_88ad7ebaec20
20/11/30 23:07:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4ba0e765_96f1_4d5a_8937_88ad7ebaec20` AS `q01`
WHERE (0 = 1)
20/11/30 23:07:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361
20/11/30 23:07:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361` AS `q02`
WHERE (0 = 1)
20/11/30 23:07:29 INFO SparkSqlParser: Parsing command: SELECT COUNT(*) AS `n`
FROM `sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361`
20/11/30 23:07:30 INFO SparkSqlParser: Parsing command: SELECT COUNT(*) AS `n`
FROM `sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361`
20/11/30 23:07:30 INFO SparkSqlParser: Parsing command: SELECT COUNT(*) AS `n`
FROM `sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361`
LIMIT 11
20/11/30 23:07:30 INFO SparkSqlParser: Parsing command: SELECT COUNT(*) AS `n`
FROM `sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361`
LIMIT 11
20/11/30 23:07:30 INFO CodeGenerator: Code generated in 34.721668 ms
20/11/30 23:07:30 INFO SparkContext: Starting job: collect at utils.scala:116
20/11/30 23:07:30 INFO DAGScheduler: Registering RDD 34 (collect at utils.scala:116)
20/11/30 23:07:30 INFO DAGScheduler: Got job 4 (collect at utils.scala:116) with 1 output partitions
20/11/30 23:07:30 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:116)
20/11/30 23:07:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
20/11/30 23:07:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
20/11/30 23:07:30 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at utils.scala:116), which has no missing parents
20/11/30 23:07:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 54.5 KB, free 912.2 MB)
20/11/30 23:07:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.6 KB, free 912.2 MB)
20/11/30 23:07:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52718 (size: 18.6 KB, free: 912.3 MB)
20/11/30 23:07:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
20/11/30 23:07:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at utils.scala:116)
20/11/30 23:07:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 161
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 162
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 163
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 164
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 165
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 166
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 167
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 168
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 169
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 170
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 171
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 172
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 173
20/11/30 23:07:30 INFO ContextCleaner: Cleaned shuffle 1
20/11/30 23:07:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52718 in memory (size: 4.7 KB, free: 912.3 MB)
20/11/30 23:07:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 912.3 MB)
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 270
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 271
20/11/30 23:07:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 912.3 MB)
20/11/30 23:07:30 INFO ContextCleaner: Cleaned accumulator 320
20/11/30 23:07:31 WARN TaskSetManager: Stage 6 contains a task of very large size (23724 KB). The maximum recommended task size is 100 KB.
20/11/30 23:07:31 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 24293663 bytes)
20/11/30 23:07:31 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/11/30 23:07:33 INFO CodeGenerator: Code generated in 89.090713 ms
20/11/30 23:07:34 INFO MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 6.3 MB, free 905.9 MB)
20/11/30 23:07:34 INFO BlockManagerInfo: Added rdd_16_0 in memory on 127.0.0.1:52718 (size: 6.3 MB, free: 905.9 MB)
20/11/30 23:07:34 INFO CodeGenerator: Code generated in 7.589276 ms
20/11/30 23:07:34 INFO CodeGenerator: Code generated in 87.097454 ms
20/11/30 23:07:34 INFO CodeGenerator: Code generated in 261.456109 ms
20/11/30 23:07:34 INFO CodeGenerator: Code generated in 18.580996 ms
20/11/30 23:07:36 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3339 bytes result sent to driver
20/11/30 23:07:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6164 ms on localhost (executor driver) (1/1)
20/11/30 23:07:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/11/30 23:07:36 INFO DAGScheduler: ShuffleMapStage 6 (collect at utils.scala:116) finished in 6.165 s
20/11/30 23:07:36 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:07:36 INFO DAGScheduler: running: Set()
20/11/30 23:07:36 INFO DAGScheduler: waiting: Set(ResultStage 7)
20/11/30 23:07:36 INFO DAGScheduler: failed: Set()
20/11/30 23:07:36 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[37] at collect at utils.scala:116), which has no missing parents
20/11/30 23:07:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.9 KB, free 905.9 MB)
20/11/30 23:07:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 905.9 MB)
20/11/30 23:07:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 905.9 MB)
20/11/30 23:07:36 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
20/11/30 23:07:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at collect at utils.scala:116)
20/11/30 23:07:36 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/11/30 23:07:36 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, ANY, 5860 bytes)
20/11/30 23:07:36 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/11/30 23:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/30 23:07:36 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2018 bytes result sent to driver
20/11/30 23:07:36 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
20/11/30 23:07:36 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/11/30 23:07:36 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:116) finished in 0.008 s
20/11/30 23:07:36 INFO DAGScheduler: Job 4 finished: collect at utils.scala:116, took 6.218174 s
20/11/30 23:07:36 INFO CodeGenerator: Code generated in 29.635783 ms
20/11/30 23:07:36 INFO CodeGenerator: Code generated in 29.727374 ms
20/11/30 23:07:36 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:07:36 INFO DAGScheduler: Registering RDD 40 (count at utils.scala:116)
20/11/30 23:07:36 INFO DAGScheduler: Got job 5 (count at utils.scala:116) with 1 output partitions
20/11/30 23:07:36 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:116)
20/11/30 23:07:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
20/11/30 23:07:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
20/11/30 23:07:36 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[40] at count at utils.scala:116), which has no missing parents
20/11/30 23:07:36 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 51.8 KB, free 905.8 MB)
20/11/30 23:07:36 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.4 KB, free 905.8 MB)
20/11/30 23:07:36 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52718 (size: 17.4 KB, free: 905.9 MB)
20/11/30 23:07:36 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
20/11/30 23:07:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[40] at count at utils.scala:116)
20/11/30 23:07:36 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/11/30 23:07:37 WARN TaskSetManager: Stage 8 contains a task of very large size (23724 KB). The maximum recommended task size is 100 KB.
20/11/30 23:07:37 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 24293749 bytes)
20/11/30 23:07:37 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/11/30 23:07:37 INFO BlockManager: Found block rdd_16_0 locally
20/11/30 23:07:38 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2704 bytes result sent to driver
20/11/30 23:07:38 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 2177 ms on localhost (executor driver) (1/1)
20/11/30 23:07:38 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/11/30 23:07:38 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:116) finished in 2.179 s
20/11/30 23:07:38 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:07:38 INFO DAGScheduler: running: Set()
20/11/30 23:07:38 INFO DAGScheduler: waiting: Set(ResultStage 9)
20/11/30 23:07:38 INFO DAGScheduler: failed: Set()
20/11/30 23:07:38 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[43] at count at utils.scala:116), which has no missing parents
20/11/30 23:07:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.2 KB, free 905.8 MB)
20/11/30 23:07:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.4 KB, free 905.8 MB)
20/11/30 23:07:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:52718 (size: 4.4 KB, free: 905.9 MB)
20/11/30 23:07:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
20/11/30 23:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[43] at count at utils.scala:116)
20/11/30 23:07:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/11/30 23:07:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 5946 bytes)
20/11/30 23:07:39 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/11/30 23:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/30 23:07:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2358 bytes result sent to driver
20/11/30 23:07:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
20/11/30 23:07:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/11/30 23:07:39 INFO DAGScheduler: ResultStage 9 (count at utils.scala:116) finished in 0.009 s
20/11/30 23:07:39 INFO DAGScheduler: Job 5 finished: count at utils.scala:116, took 2.210855 s
20/11/30 23:07:39 INFO SparkSqlParser: Parsing command: SELECT COUNT(*) AS `n`
FROM `sparklyr_tmp_481af02a_3992_46a4_8ebc_20dd39912361`
20/11/30 23:08:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4ba0e765_96f1_4d5a_8937_88ad7ebaec20`
20/11/30 23:09:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:09:48 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:09:48 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:09:48 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:09:48 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:09:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:09:48 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 449
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 450
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 451
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 452
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 453
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 454
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 455
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 456
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 457
20/11/30 23:09:48 INFO ContextCleaner: Cleaned shuffle 3
20/11/30 23:09:48 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52718 in memory (size: 17.4 KB, free: 905.9 MB)
20/11/30 23:09:48 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:09:48 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:52718 in memory (size: 4.4 KB, free: 905.9 MB)
20/11/30 23:09:48 INFO DAGScheduler: Got job 6 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:09:48 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:46)
20/11/30 23:09:48 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:09:48 INFO DAGScheduler: Missing parents: List()
20/11/30 23:09:48 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[49] at map at utils.scala:43), which has no missing parents
20/11/30 23:09:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 905.9 MB)
20/11/30 23:09:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 905.9 MB)
20/11/30 23:09:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 905.9 MB)
20/11/30 23:09:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
20/11/30 23:09:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[49] at map at utils.scala:43)
20/11/30 23:09:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/11/30 23:09:48 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 905.9 MB)
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 433
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 434
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 435
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 436
20/11/30 23:09:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6554 bytes)
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 437
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 438
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 439
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 440
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 441
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 442
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 443
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 444
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 445
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 446
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 447
20/11/30 23:09:48 INFO ContextCleaner: Cleaned accumulator 448
20/11/30 23:09:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/11/30 23:09:48 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1437 bytes result sent to driver
20/11/30 23:09:48 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 12 ms on localhost (executor driver) (1/1)
20/11/30 23:09:48 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/11/30 23:09:48 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:46) finished in 0.012 s
20/11/30 23:09:48 INFO DAGScheduler: Job 6 finished: collect at utils.scala:46, took 0.023431 s
20/11/30 23:10:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:10:00 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:10:00 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:10:00 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:10:00 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:10:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:10:00 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:10:00 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:10:00 INFO DAGScheduler: Got job 7 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:10:00 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:46)
20/11/30 23:10:00 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:10:00 INFO DAGScheduler: Missing parents: List()
20/11/30 23:10:00 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[55] at map at utils.scala:43), which has no missing parents
20/11/30 23:10:00 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.7 KB, free 905.9 MB)
20/11/30 23:10:00 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.6 KB, free 905.9 MB)
20/11/30 23:10:00 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 905.9 MB)
20/11/30 23:10:00 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[55] at map at utils.scala:43)
20/11/30 23:10:00 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/11/30 23:10:00 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6554 bytes)
20/11/30 23:10:00 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/11/30 23:10:00 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1350 bytes result sent to driver
20/11/30 23:10:00 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
20/11/30 23:10:00 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/11/30 23:10:00 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:46) finished in 0.009 s
20/11/30 23:10:00 INFO DAGScheduler: Job 7 finished: collect at utils.scala:46, took 0.018418 s
20/11/30 23:10:00 INFO SparkSqlParser: Parsing command: DROP TABLE `tbl_num_full`
20/11/30 23:10:00 INFO SparkSqlParser: Parsing command: `tbl_num_full`
20/11/30 23:10:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 905.9 MB)
20/11/30 23:10:03 INFO ContextCleaner: Cleaned accumulator 604
20/11/30 23:10:03 INFO ContextCleaner: Cleaned accumulator 605
20/11/30 23:10:03 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 905.9 MB)
20/11/30 23:10:03 INFO ContextCleaner: Cleaned accumulator 554
20/11/30 23:10:03 INFO ContextCleaner: Cleaned accumulator 555
20/11/30 23:10:03 INFO SparkSqlParser: Parsing command: tbl_num_full
20/11/30 23:10:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full` AS `q01`
WHERE (0 = 1)
20/11/30 23:10:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full`
20/11/30 23:10:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full` AS `q01`
WHERE (0 = 1)
20/11/30 23:10:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:10:04 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:10:04 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:10:04 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:10:04 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:10:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:10:04 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:10:04 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:10:04 INFO DAGScheduler: Registering RDD 64 (count at utils.scala:116)
20/11/30 23:10:04 INFO DAGScheduler: Got job 8 (count at utils.scala:116) with 1 output partitions
20/11/30 23:10:04 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:116)
20/11/30 23:10:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/11/30 23:10:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/11/30 23:10:04 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[64] at count at utils.scala:116), which has no missing parents
20/11/30 23:10:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.9 KB, free 905.9 MB)
20/11/30 23:10:04 INFO ContextCleaner: Cleaned accumulator 656
20/11/30 23:10:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.7 KB, free 905.9 MB)
20/11/30 23:10:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:52718 (size: 4.7 KB, free: 905.9 MB)
20/11/30 23:10:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[64] at count at utils.scala:116)
20/11/30 23:10:04 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/11/30 23:10:04 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6572 bytes)
20/11/30 23:10:04 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/11/30 23:10:04 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1806 bytes result sent to driver
20/11/30 23:10:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 11 ms on localhost (executor driver) (1/1)
20/11/30 23:10:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/11/30 23:10:04 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:116) finished in 0.012 s
20/11/30 23:10:04 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:10:04 INFO DAGScheduler: running: Set()
20/11/30 23:10:04 INFO DAGScheduler: waiting: Set(ResultStage 13)
20/11/30 23:10:04 INFO DAGScheduler: failed: Set()
20/11/30 23:10:04 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[67] at count at utils.scala:116), which has no missing parents
20/11/30 23:10:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 905.9 MB)
20/11/30 23:10:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 905.9 MB)
20/11/30 23:10:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 905.9 MB)
20/11/30 23:10:04 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[67] at count at utils.scala:116)
20/11/30 23:10:04 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/11/30 23:10:04 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 5946 bytes)
20/11/30 23:10:04 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/11/30 23:10:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/30 23:10:04 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2042 bytes result sent to driver
20/11/30 23:10:04 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
20/11/30 23:10:04 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/11/30 23:10:04 INFO DAGScheduler: ResultStage 13 (count at utils.scala:116) finished in 0.006 s
20/11/30 23:10:04 INFO DAGScheduler: Job 8 finished: count at utils.scala:116, took 0.068408 s
20/11/30 23:10:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_full`
20/11/30 23:10:06 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3
20/11/30 23:10:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3` AS `q01`
WHERE (0 = 1)
20/11/30 23:10:06 INFO SparkSqlParser: Parsing command: sparklyr_tmp_a9fee77a_c78f_4c9a_a10c_46fb8749105c
20/11/30 23:10:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_a9fee77a_c78f_4c9a_a10c_46fb8749105c` AS `q02`
WHERE (0 = 1)
20/11/30 23:10:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3`
20/11/30 23:10:09 INFO CodeGenerator: Code generated in 121.760742 ms
20/11/30 23:10:10 INFO SparkContext: Starting job: first at PCA.scala:43
20/11/30 23:10:10 INFO DAGScheduler: Got job 9 (first at PCA.scala:43) with 1 output partitions
20/11/30 23:10:10 INFO DAGScheduler: Final stage: ResultStage 14 (first at PCA.scala:43)
20/11/30 23:10:10 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:10:10 INFO DAGScheduler: Missing parents: List()
20/11/30 23:10:10 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[74] at map at PCA.scala:95), which has no missing parents
20/11/30 23:10:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 94.6 KB, free 905.8 MB)
20/11/30 23:10:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 29.2 KB, free 905.7 MB)
20/11/30 23:10:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:52718 (size: 29.2 KB, free: 905.9 MB)
20/11/30 23:10:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[74] at map at PCA.scala:95)
20/11/30 23:10:10 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/11/30 23:10:10 WARN TaskSetManager: Stage 14 contains a task of very large size (22860 KB). The maximum recommended task size is 100 KB.
20/11/30 23:10:10 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 23408913 bytes)
20/11/30 23:10:10 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
20/11/30 23:10:11 INFO CodeGenerator: Code generated in 29.652149 ms
20/11/30 23:10:11 INFO MemoryStore: Block rdd_60_0 stored as values in memory (estimated size 6.2 MB, free 899.5 MB)
20/11/30 23:10:11 INFO BlockManagerInfo: Added rdd_60_0 in memory on 127.0.0.1:52718 (size: 6.2 MB, free: 899.7 MB)
20/11/30 23:10:11 INFO CodeGenerator: Code generated in 43.477602 ms
20/11/30 23:10:11 INFO CodeGenerator: Code generated in 81.578026 ms
20/11/30 23:10:11 INFO CodeGenerator: Code generated in 9.055656 ms
20/11/30 23:10:13 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3003 bytes result sent to driver
20/11/30 23:10:13 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 3308 ms on localhost (executor driver) (1/1)
20/11/30 23:10:13 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/11/30 23:10:13 INFO DAGScheduler: ResultStage 14 (first at PCA.scala:43) finished in 3.308 s
20/11/30 23:10:13 INFO DAGScheduler: Job 9 finished: first at PCA.scala:43, took 3.319149 s
20/11/30 23:10:13 INFO SparkContext: Starting job: first at RowMatrix.scala:61
20/11/30 23:10:13 INFO DAGScheduler: Got job 10 (first at RowMatrix.scala:61) with 1 output partitions
20/11/30 23:10:13 INFO DAGScheduler: Final stage: ResultStage 15 (first at RowMatrix.scala:61)
20/11/30 23:10:13 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:10:13 INFO DAGScheduler: Missing parents: List()
20/11/30 23:10:13 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[74] at map at PCA.scala:95), which has no missing parents
20/11/30 23:10:13 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 94.6 KB, free 899.4 MB)
20/11/30 23:10:13 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.3 KB, free 899.4 MB)
20/11/30 23:10:13 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:52718 (size: 29.3 KB, free: 899.6 MB)
20/11/30 23:10:13 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[74] at map at PCA.scala:95)
20/11/30 23:10:13 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/11/30 23:10:13 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:52718 in memory (size: 4.7 KB, free: 899.6 MB)
20/11/30 23:10:13 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 899.6 MB)
20/11/30 23:10:13 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:52718 in memory (size: 29.2 KB, free: 899.7 MB)
20/11/30 23:10:13 WARN TaskSetManager: Stage 15 contains a task of very large size (22860 KB). The maximum recommended task size is 100 KB.
20/11/30 23:10:13 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 23408913 bytes)
20/11/30 23:10:13 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
20/11/30 23:10:14 INFO BlockManager: Found block rdd_60_0 locally
20/11/30 23:10:15 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2354 bytes result sent to driver
20/11/30 23:10:15 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 2035 ms on localhost (executor driver) (1/1)
20/11/30 23:10:15 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/11/30 23:10:15 INFO DAGScheduler: ResultStage 15 (first at RowMatrix.scala:61) finished in 2.036 s
20/11/30 23:10:15 INFO DAGScheduler: Job 10 finished: first at RowMatrix.scala:61, took 2.044371 s
20/11/30 23:10:15 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:419
20/11/30 23:10:15 INFO DAGScheduler: Got job 11 (treeAggregate at RowMatrix.scala:419) with 1 output partitions
20/11/30 23:10:15 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at RowMatrix.scala:419)
20/11/30 23:10:15 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:10:15 INFO DAGScheduler: Missing parents: List()
20/11/30 23:10:15 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[75] at treeAggregate at RowMatrix.scala:419), which has no missing parents
20/11/30 23:10:15 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 95.4 KB, free 899.4 MB)
20/11/30 23:10:15 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.7 KB, free 899.4 MB)
20/11/30 23:10:15 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:52718 (size: 29.7 KB, free: 899.6 MB)
20/11/30 23:10:15 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[75] at treeAggregate at RowMatrix.scala:419)
20/11/30 23:10:15 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/11/30 23:10:15 WARN TaskSetManager: Stage 16 contains a task of very large size (22860 KB). The maximum recommended task size is 100 KB.
20/11/30 23:10:15 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 23408921 bytes)
20/11/30 23:10:15 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
20/11/30 23:10:16 INFO BlockManager: Found block rdd_60_0 locally
20/11/30 23:10:18 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 6353 bytes result sent to driver
20/11/30 23:10:18 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 2819 ms on localhost (executor driver) (1/1)
20/11/30 23:10:18 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/11/30 23:10:18 INFO DAGScheduler: ResultStage 16 (treeAggregate at RowMatrix.scala:419) finished in 2.820 s
20/11/30 23:10:18 INFO DAGScheduler: Job 11 finished: treeAggregate at RowMatrix.scala:419, took 2.828442 s
20/11/30 23:10:18 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:122
20/11/30 23:10:18 INFO DAGScheduler: Got job 12 (treeAggregate at RowMatrix.scala:122) with 1 output partitions
20/11/30 23:10:18 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at RowMatrix.scala:122)
20/11/30 23:10:18 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:10:18 INFO DAGScheduler: Missing parents: List()
20/11/30 23:10:18 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[76] at treeAggregate at RowMatrix.scala:122), which has no missing parents
20/11/30 23:10:18 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 109.6 KB, free 899.3 MB)
20/11/30 23:10:18 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 29.8 KB, free 899.3 MB)
20/11/30 23:10:18 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:52718 (size: 29.8 KB, free: 899.6 MB)
20/11/30 23:10:18 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
20/11/30 23:10:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[76] at treeAggregate at RowMatrix.scala:122)
20/11/30 23:10:18 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/11/30 23:10:19 WARN TaskSetManager: Stage 17 contains a task of very large size (22860 KB). The maximum recommended task size is 100 KB.
20/11/30 23:10:19 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 23408921 bytes)
20/11/30 23:10:19 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
20/11/30 23:10:19 INFO BlockManager: Found block rdd_60_0 locally
20/11/30 23:10:21 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 16902 bytes result sent to driver
20/11/30 23:10:21 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 2600 ms on localhost (executor driver) (1/1)
20/11/30 23:10:21 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/11/30 23:10:21 INFO DAGScheduler: ResultStage 17 (treeAggregate at RowMatrix.scala:122) finished in 2.601 s
20/11/30 23:10:21 INFO DAGScheduler: Job 12 finished: treeAggregate at RowMatrix.scala:122, took 2.611420 s
20/11/30 23:10:22 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
20/11/30 23:10:22 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
20/11/30 23:30:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3`
20/11/30 23:30:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3`
20/11/30 23:30:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3`
LIMIT 11
20/11/30 23:30:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3`
LIMIT 11
20/11/30 23:30:53 INFO CodeGenerator: Code generated in 36.625058 ms
20/11/30 23:30:53 INFO SparkContext: Starting job: collect at utils.scala:116
20/11/30 23:30:53 INFO DAGScheduler: Got job 13 (collect at utils.scala:116) with 1 output partitions
20/11/30 23:30:53 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:116)
20/11/30 23:30:53 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:30:53 INFO DAGScheduler: Missing parents: List()
20/11/30 23:30:53 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[79] at collect at utils.scala:116), which has no missing parents
20/11/30 23:30:53 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 61.2 KB, free 899.2 MB)
20/11/30 23:30:53 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 18.6 KB, free 899.2 MB)
20/11/30 23:30:53 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:52718 (size: 18.6 KB, free: 899.6 MB)
20/11/30 23:30:53 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
20/11/30 23:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[79] at collect at utils.scala:116)
20/11/30 23:30:53 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
20/11/30 23:30:54 WARN TaskSetManager: Stage 18 contains a task of very large size (22860 KB). The maximum recommended task size is 100 KB.
20/11/30 23:30:54 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 23408858 bytes)
20/11/30 23:30:54 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
20/11/30 23:30:54 INFO BlockManager: Found block rdd_60_0 locally
20/11/30 23:30:55 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2662 bytes result sent to driver
20/11/30 23:30:55 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 2175 ms on localhost (executor driver) (1/1)
20/11/30 23:30:55 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/11/30 23:30:55 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:116) finished in 2.176 s
20/11/30 23:30:55 INFO DAGScheduler: Job 13 finished: collect at utils.scala:116, took 2.184130 s
20/11/30 23:30:55 INFO CodeGenerator: Code generated in 29.006384 ms
20/11/30 23:30:55 INFO CodeGenerator: Code generated in 13.578803 ms
20/11/30 23:30:55 INFO CodeGenerator: Code generated in 14.682735 ms
20/11/30 23:30:55 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:30:55 INFO DAGScheduler: Registering RDD 82 (count at utils.scala:116)
20/11/30 23:30:55 INFO DAGScheduler: Got job 14 (count at utils.scala:116) with 1 output partitions
20/11/30 23:30:55 INFO DAGScheduler: Final stage: ResultStage 20 (count at utils.scala:116)
20/11/30 23:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
20/11/30 23:30:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
20/11/30 23:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[82] at count at utils.scala:116), which has no missing parents
20/11/30 23:30:55 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 49.0 KB, free 899.1 MB)
20/11/30 23:30:55 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.4 KB, free 899.1 MB)
20/11/30 23:30:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:52718 (size: 16.4 KB, free: 899.6 MB)
20/11/30 23:30:55 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
20/11/30 23:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[82] at count at utils.scala:116)
20/11/30 23:30:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/11/30 23:30:56 WARN TaskSetManager: Stage 19 contains a task of very large size (22860 KB). The maximum recommended task size is 100 KB.
20/11/30 23:30:56 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 23408933 bytes)
20/11/30 23:30:56 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
20/11/30 23:30:56 INFO BlockManager: Found block rdd_60_0 locally
20/11/30 23:30:57 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2361 bytes result sent to driver
20/11/30 23:30:57 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 2008 ms on localhost (executor driver) (1/1)
20/11/30 23:30:57 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/11/30 23:30:57 INFO DAGScheduler: ShuffleMapStage 19 (count at utils.scala:116) finished in 2.009 s
20/11/30 23:30:57 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:30:57 INFO DAGScheduler: running: Set()
20/11/30 23:30:57 INFO DAGScheduler: waiting: Set(ResultStage 20)
20/11/30 23:30:57 INFO DAGScheduler: failed: Set()
20/11/30 23:30:57 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[85] at count at utils.scala:116), which has no missing parents
20/11/30 23:30:57 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 8.9 KB, free 899.1 MB)
20/11/30 23:30:57 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.2 KB, free 899.1 MB)
20/11/30 23:30:57 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:52718 (size: 4.2 KB, free: 899.6 MB)
20/11/30 23:30:57 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
20/11/30 23:30:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[85] at count at utils.scala:116)
20/11/30 23:30:57 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
20/11/30 23:30:57 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, ANY, 5946 bytes)
20/11/30 23:30:57 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
20/11/30 23:30:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/30 23:30:57 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2200 bytes result sent to driver
20/11/30 23:30:57 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 5 ms on localhost (executor driver) (1/1)
20/11/30 23:30:57 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/11/30 23:30:57 INFO DAGScheduler: ResultStage 20 (count at utils.scala:116) finished in 0.006 s
20/11/30 23:30:57 INFO DAGScheduler: Job 14 finished: count at utils.scala:116, took 2.030499 s
20/11/30 23:30:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ef5533b_29bf_4500_a6f2_7de55db9ace3`
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 335
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:52718 in memory (size: 4.2 KB, free: 899.6 MB)
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:52718 in memory (size: 16.4 KB, free: 899.6 MB)
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1017
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1018
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1019
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1020
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1021
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1022
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1023
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1024
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1025
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1026
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1027
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1028
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1029
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1030
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1031
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1032
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 1033
20/11/30 23:35:54 INFO ContextCleaner: Cleaned shuffle 5
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:52718 in memory (size: 18.6 KB, free: 899.6 MB)
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:52718 in memory (size: 29.8 KB, free: 899.6 MB)
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:52718 in memory (size: 29.7 KB, free: 899.7 MB)
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:52718 in memory (size: 29.3 KB, free: 899.7 MB)
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 770
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 769
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 768
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 767
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 766
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 765
20/11/30 23:35:54 INFO ContextCleaner: Cleaned shuffle 4
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 668
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 667
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 666
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 665
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 664
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 663
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 662
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 661
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 660
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 659
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 658
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 657
20/11/30 23:35:54 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52718 in memory (size: 18.6 KB, free: 899.7 MB)
20/11/30 23:35:54 INFO ContextCleaner: Cleaned shuffle 2
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 336
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 334
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 333
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 332
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 331
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 330
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 329
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 328
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 327
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 326
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 325
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 324
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 323
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 322
20/11/30 23:35:54 INFO ContextCleaner: Cleaned accumulator 321
20/11/30 23:41:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:41:53 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:41:53 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:41:53 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:41:53 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:41:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:41:53 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:41:53 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:41:53 INFO DAGScheduler: Got job 15 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:41:53 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:46)
20/11/30 23:41:53 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:41:53 INFO DAGScheduler: Missing parents: List()
20/11/30 23:41:53 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[91] at map at utils.scala:43), which has no missing parents
20/11/30 23:41:53 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.7 KB, free 899.7 MB)
20/11/30 23:41:53 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.6 KB, free 899.7 MB)
20/11/30 23:41:53 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 899.7 MB)
20/11/30 23:41:53 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
20/11/30 23:41:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[91] at map at utils.scala:43)
20/11/30 23:41:53 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/11/30 23:41:53 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6746 bytes)
20/11/30 23:41:53 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
20/11/30 23:41:53 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1457 bytes result sent to driver
20/11/30 23:41:53 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 8 ms on localhost (executor driver) (1/1)
20/11/30 23:41:53 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/11/30 23:41:53 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:46) finished in 0.009 s
20/11/30 23:41:53 INFO DAGScheduler: Job 15 finished: collect at utils.scala:46, took 0.015319 s
20/11/30 23:41:54 INFO SparkSqlParser: Parsing command: tbl_num_less_30
20/11/30 23:41:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_less_30` AS `q01`
WHERE (0 = 1)
20/11/30 23:41:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_less_30`
20/11/30 23:41:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_less_30` AS `q01`
WHERE (0 = 1)
20/11/30 23:41:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:41:54 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:41:54 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:41:54 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:41:54 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:41:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:41:54 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:41:54 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:41:54 INFO DAGScheduler: Registering RDD 99 (count at utils.scala:116)
20/11/30 23:41:54 INFO DAGScheduler: Got job 16 (count at utils.scala:116) with 1 output partitions
20/11/30 23:41:54 INFO DAGScheduler: Final stage: ResultStage 23 (count at utils.scala:116)
20/11/30 23:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
20/11/30 23:41:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
20/11/30 23:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[99] at count at utils.scala:116), which has no missing parents
20/11/30 23:41:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 8.9 KB, free 899.7 MB)
20/11/30 23:41:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.7 KB, free 899.7 MB)
20/11/30 23:41:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:52718 (size: 4.7 KB, free: 899.7 MB)
20/11/30 23:41:54 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
20/11/30 23:41:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[99] at count at utils.scala:116)
20/11/30 23:41:54 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
20/11/30 23:41:54 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6827 bytes)
20/11/30 23:41:54 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
20/11/30 23:41:54 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1806 bytes result sent to driver
20/11/30 23:41:54 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 16 ms on localhost (executor driver) (1/1)
20/11/30 23:41:54 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/11/30 23:41:54 INFO DAGScheduler: ShuffleMapStage 22 (count at utils.scala:116) finished in 0.018 s
20/11/30 23:41:54 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:41:54 INFO DAGScheduler: running: Set()
20/11/30 23:41:54 INFO DAGScheduler: waiting: Set(ResultStage 23)
20/11/30 23:41:54 INFO DAGScheduler: failed: Set()
20/11/30 23:41:54 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[102] at count at utils.scala:116), which has no missing parents
20/11/30 23:41:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.0 KB, free 899.7 MB)
20/11/30 23:41:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 899.7 MB)
20/11/30 23:41:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 899.7 MB)
20/11/30 23:41:54 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
20/11/30 23:41:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[102] at count at utils.scala:116)
20/11/30 23:41:54 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
20/11/30 23:41:54 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, ANY, 5947 bytes)
20/11/30 23:41:54 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
20/11/30 23:41:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:41:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/30 23:41:54 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2042 bytes result sent to driver
20/11/30 23:41:54 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 7 ms on localhost (executor driver) (1/1)
20/11/30 23:41:54 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/11/30 23:41:54 INFO DAGScheduler: ResultStage 23 (count at utils.scala:116) finished in 0.008 s
20/11/30 23:41:54 INFO DAGScheduler: Job 16 finished: count at utils.scala:116, took 0.041889 s
20/11/30 23:42:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:42:04 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:04 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:04 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:04 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:42:04 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:42:04 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:42:04 INFO DAGScheduler: Got job 17 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:42:04 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:46)
20/11/30 23:42:04 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:42:04 INFO DAGScheduler: Missing parents: List()
20/11/30 23:42:04 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[108] at map at utils.scala:43), which has no missing parents
20/11/30 23:42:04 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 8.7 KB, free 899.7 MB)
20/11/30 23:42:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.6 KB, free 899.7 MB)
20/11/30 23:42:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 899.7 MB)
20/11/30 23:42:04 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
20/11/30 23:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[108] at map at utils.scala:43)
20/11/30 23:42:04 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
20/11/30 23:42:04 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6808 bytes)
20/11/30 23:42:04 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
20/11/30 23:42:04 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1475 bytes result sent to driver
20/11/30 23:42:04 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 8 ms on localhost (executor driver) (1/1)
20/11/30 23:42:04 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/11/30 23:42:04 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:46) finished in 0.009 s
20/11/30 23:42:04 INFO DAGScheduler: Job 17 finished: collect at utils.scala:46, took 0.015965 s
20/11/30 23:42:05 INFO SparkSqlParser: Parsing command: tbl_num_more_30
20/11/30 23:42:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_more_30` AS `q02`
WHERE (0 = 1)
20/11/30 23:42:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_more_30`
20/11/30 23:42:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_more_30` AS `q01`
WHERE (0 = 1)
20/11/30 23:42:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:42:06 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:06 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:42:06 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:42:06 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:42:06 INFO DAGScheduler: Registering RDD 116 (count at utils.scala:116)
20/11/30 23:42:06 INFO DAGScheduler: Got job 18 (count at utils.scala:116) with 1 output partitions
20/11/30 23:42:06 INFO DAGScheduler: Final stage: ResultStage 26 (count at utils.scala:116)
20/11/30 23:42:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
20/11/30 23:42:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
20/11/30 23:42:06 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[116] at count at utils.scala:116), which has no missing parents
20/11/30 23:42:06 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 8.9 KB, free 899.7 MB)
20/11/30 23:42:06 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.7 KB, free 899.7 MB)
20/11/30 23:42:06 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:52718 (size: 4.7 KB, free: 899.7 MB)
20/11/30 23:42:06 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
20/11/30 23:42:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[116] at count at utils.scala:116)
20/11/30 23:42:06 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
20/11/30 23:42:06 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6889 bytes)
20/11/30 23:42:06 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
20/11/30 23:42:06 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1806 bytes result sent to driver
20/11/30 23:42:06 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 10 ms on localhost (executor driver) (1/1)
20/11/30 23:42:06 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/11/30 23:42:06 INFO DAGScheduler: ShuffleMapStage 25 (count at utils.scala:116) finished in 0.010 s
20/11/30 23:42:06 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:42:06 INFO DAGScheduler: running: Set()
20/11/30 23:42:06 INFO DAGScheduler: waiting: Set(ResultStage 26)
20/11/30 23:42:06 INFO DAGScheduler: failed: Set()
20/11/30 23:42:06 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[119] at count at utils.scala:116), which has no missing parents
20/11/30 23:42:06 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 899.7 MB)
20/11/30 23:42:06 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 899.6 MB)
20/11/30 23:42:06 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 899.7 MB)
20/11/30 23:42:06 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
20/11/30 23:42:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[119] at count at utils.scala:116)
20/11/30 23:42:06 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
20/11/30 23:42:06 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, ANY, 5947 bytes)
20/11/30 23:42:06 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
20/11/30 23:42:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:42:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/30 23:42:06 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2129 bytes result sent to driver
20/11/30 23:42:06 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 6 ms on localhost (executor driver) (1/1)
20/11/30 23:42:06 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
20/11/30 23:42:06 INFO DAGScheduler: ResultStage 26 (count at utils.scala:116) finished in 0.007 s
20/11/30 23:42:06 INFO DAGScheduler: Job 18 finished: count at utils.scala:116, took 0.036175 s
20/11/30 23:42:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:42:32 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:32 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:32 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:32 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:42:32 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:42:32 INFO SparkContext: Starting job: collect at utils.scala:46
20/11/30 23:42:32 INFO DAGScheduler: Got job 19 (collect at utils.scala:46) with 1 output partitions
20/11/30 23:42:32 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:46)
20/11/30 23:42:32 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:42:32 INFO DAGScheduler: Missing parents: List()
20/11/30 23:42:32 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[125] at map at utils.scala:43), which has no missing parents
20/11/30 23:42:32 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 8.7 KB, free 899.6 MB)
20/11/30 23:42:32 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 4.6 KB, free 899.6 MB)
20/11/30 23:42:32 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:52718 (size: 4.6 KB, free: 899.7 MB)
20/11/30 23:42:32 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
20/11/30 23:42:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[125] at map at utils.scala:43)
20/11/30 23:42:32 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
20/11/30 23:42:32 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6870 bytes)
20/11/30 23:42:32 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
20/11/30 23:42:32 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1493 bytes result sent to driver
20/11/30 23:42:32 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 6 ms on localhost (executor driver) (1/1)
20/11/30 23:42:32 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
20/11/30 23:42:32 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:46) finished in 0.006 s
20/11/30 23:42:32 INFO DAGScheduler: Job 19 finished: collect at utils.scala:46, took 0.012531 s
20/11/30 23:42:33 INFO ContextCleaner: Cleaned accumulator 1189
20/11/30 23:42:33 INFO ContextCleaner: Cleaned accumulator 1130
20/11/30 23:42:33 INFO ContextCleaner: Cleaned accumulator 1131
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1182
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1183
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1184
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1185
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1186
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1187
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1188
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1190
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1191
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1192
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1193
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1194
20/11/30 23:42:34 INFO ContextCleaner: Cleaned shuffle 6
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:52718 in memory (size: 4.7 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1291
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1292
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:52718 in memory (size: 4.6 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1343
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1344
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1345
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1346
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1347
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1348
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1349
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1350
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1351
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1352
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1353
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1354
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1355
20/11/30 23:42:34 INFO ContextCleaner: Cleaned shuffle 7
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:52718 in memory (size: 4.7 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1452
20/11/30 23:42:34 INFO ContextCleaner: Cleaned accumulator 1453
20/11/30 23:42:34 INFO SparkSqlParser: Parsing command: tbl_num_no_rdms
20/11/30 23:42:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_no_rdms` AS `q02`
WHERE (0 = 1)
20/11/30 23:42:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_no_rdms`
20/11/30 23:42:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_no_rdms` AS `q01`
WHERE (0 = 1)
20/11/30 23:42:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/11/30 23:42:34 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:34 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:34 INFO HiveMetaStore: 0: get_database: default
20/11/30 23:42:34 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_database: default	
20/11/30 23:42:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
20/11/30 23:42:34 INFO audit: ugi=macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
20/11/30 23:42:34 INFO SparkContext: Starting job: count at utils.scala:116
20/11/30 23:42:34 INFO DAGScheduler: Registering RDD 133 (count at utils.scala:116)
20/11/30 23:42:34 INFO DAGScheduler: Got job 20 (count at utils.scala:116) with 1 output partitions
20/11/30 23:42:34 INFO DAGScheduler: Final stage: ResultStage 29 (count at utils.scala:116)
20/11/30 23:42:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
20/11/30 23:42:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
20/11/30 23:42:34 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[133] at count at utils.scala:116), which has no missing parents
20/11/30 23:42:34 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 8.9 KB, free 899.7 MB)
20/11/30 23:42:34 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.7 KB, free 899.7 MB)
20/11/30 23:42:34 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:52718 (size: 4.7 KB, free: 899.7 MB)
20/11/30 23:42:34 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
20/11/30 23:42:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[133] at count at utils.scala:116)
20/11/30 23:42:34 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
20/11/30 23:42:34 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6951 bytes)
20/11/30 23:42:34 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
20/11/30 23:42:35 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 1806 bytes result sent to driver
20/11/30 23:42:35 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 13 ms on localhost (executor driver) (1/1)
20/11/30 23:42:35 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
20/11/30 23:42:35 INFO DAGScheduler: ShuffleMapStage 28 (count at utils.scala:116) finished in 0.014 s
20/11/30 23:42:35 INFO DAGScheduler: looking for newly runnable stages
20/11/30 23:42:35 INFO DAGScheduler: running: Set()
20/11/30 23:42:35 INFO DAGScheduler: waiting: Set(ResultStage 29)
20/11/30 23:42:35 INFO DAGScheduler: failed: Set()
20/11/30 23:42:35 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[136] at count at utils.scala:116), which has no missing parents
20/11/30 23:42:35 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.0 KB, free 899.7 MB)
20/11/30 23:42:35 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KB, free 899.7 MB)
20/11/30 23:42:35 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:52718 (size: 3.7 KB, free: 899.7 MB)
20/11/30 23:42:35 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
20/11/30 23:42:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[136] at count at utils.scala:116)
20/11/30 23:42:35 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
20/11/30 23:42:35 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, ANY, 5947 bytes)
20/11/30 23:42:35 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
20/11/30 23:42:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/11/30 23:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/30 23:42:35 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 2042 bytes result sent to driver
20/11/30 23:42:35 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 12 ms on localhost (executor driver) (1/1)
20/11/30 23:42:35 INFO DAGScheduler: ResultStage 29 (count at utils.scala:116) finished in 0.013 s
20/11/30 23:42:35 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
20/11/30 23:42:35 INFO DAGScheduler: Job 20 finished: count at utils.scala:116, took 0.044949 s
20/11/30 23:43:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_less_30`
20/11/30 23:43:19 INFO CodeGenerator: Code generated in 51.309441 ms
20/11/30 23:43:19 INFO SparkContext: Starting job: first at PCA.scala:43
20/11/30 23:43:19 INFO DAGScheduler: Got job 21 (first at PCA.scala:43) with 1 output partitions
20/11/30 23:43:19 INFO DAGScheduler: Final stage: ResultStage 30 (first at PCA.scala:43)
20/11/30 23:43:19 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:43:19 INFO DAGScheduler: Missing parents: List()
20/11/30 23:43:19 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[141] at map at PCA.scala:95), which has no missing parents
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 90.6 KB, free 899.6 MB)
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 27.6 KB, free 899.6 MB)
20/11/30 23:43:19 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:52718 (size: 27.6 KB, free: 899.7 MB)
20/11/30 23:43:19 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
20/11/30 23:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[141] at map at PCA.scala:95)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
20/11/30 23:43:19 WARN TaskSetManager: Stage 30 contains a task of very large size (1661 KB). The maximum recommended task size is 100 KB.
20/11/30 23:43:19 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 1701717 bytes)
20/11/30 23:43:19 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
20/11/30 23:43:19 INFO MemoryStore: Block rdd_95_0 stored as values in memory (estimated size 467.8 KB, free 899.1 MB)
20/11/30 23:43:19 INFO BlockManagerInfo: Added rdd_95_0 in memory on 127.0.0.1:52718 (size: 467.8 KB, free: 899.2 MB)
20/11/30 23:43:19 INFO CodeGenerator: Code generated in 40.926574 ms
20/11/30 23:43:19 WARN Executor: 1 block locks were not released by TID = 30:
[rdd_95_0]
20/11/30 23:43:19 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 2529 bytes result sent to driver
20/11/30 23:43:19 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 234 ms on localhost (executor driver) (1/1)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
20/11/30 23:43:19 INFO DAGScheduler: ResultStage 30 (first at PCA.scala:43) finished in 0.234 s
20/11/30 23:43:19 INFO DAGScheduler: Job 21 finished: first at PCA.scala:43, took 0.244138 s
20/11/30 23:43:19 INFO SparkContext: Starting job: first at RowMatrix.scala:61
20/11/30 23:43:19 INFO DAGScheduler: Got job 22 (first at RowMatrix.scala:61) with 1 output partitions
20/11/30 23:43:19 INFO DAGScheduler: Final stage: ResultStage 31 (first at RowMatrix.scala:61)
20/11/30 23:43:19 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:43:19 INFO DAGScheduler: Missing parents: List()
20/11/30 23:43:19 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[141] at map at PCA.scala:95), which has no missing parents
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 90.6 KB, free 899.0 MB)
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 27.6 KB, free 899.0 MB)
20/11/30 23:43:19 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:52718 (size: 27.6 KB, free: 899.2 MB)
20/11/30 23:43:19 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
20/11/30 23:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[141] at map at PCA.scala:95)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
20/11/30 23:43:19 WARN TaskSetManager: Stage 31 contains a task of very large size (1661 KB). The maximum recommended task size is 100 KB.
20/11/30 23:43:19 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 1701717 bytes)
20/11/30 23:43:19 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
20/11/30 23:43:19 INFO BlockManager: Found block rdd_95_0 locally
20/11/30 23:43:19 WARN Executor: 1 block locks were not released by TID = 31:
[rdd_95_0]
20/11/30 23:43:19 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 1967 bytes result sent to driver
20/11/30 23:43:19 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 90 ms on localhost (executor driver) (1/1)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
20/11/30 23:43:19 INFO DAGScheduler: ResultStage 31 (first at RowMatrix.scala:61) finished in 0.090 s
20/11/30 23:43:19 INFO DAGScheduler: Job 22 finished: first at RowMatrix.scala:61, took 0.099894 s
20/11/30 23:43:19 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:419
20/11/30 23:43:19 INFO DAGScheduler: Got job 23 (treeAggregate at RowMatrix.scala:419) with 1 output partitions
20/11/30 23:43:19 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at RowMatrix.scala:419)
20/11/30 23:43:19 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:43:19 INFO DAGScheduler: Missing parents: List()
20/11/30 23:43:19 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[142] at treeAggregate at RowMatrix.scala:419), which has no missing parents
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 91.5 KB, free 898.9 MB)
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 28.1 KB, free 898.9 MB)
20/11/30 23:43:19 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:52718 (size: 28.1 KB, free: 899.2 MB)
20/11/30 23:43:19 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
20/11/30 23:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[142] at treeAggregate at RowMatrix.scala:419)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
20/11/30 23:43:19 WARN TaskSetManager: Stage 32 contains a task of very large size (1661 KB). The maximum recommended task size is 100 KB.
20/11/30 23:43:19 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 1701725 bytes)
20/11/30 23:43:19 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
20/11/30 23:43:19 INFO BlockManager: Found block rdd_95_0 locally
20/11/30 23:43:19 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 5857 bytes result sent to driver
20/11/30 23:43:19 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 254 ms on localhost (executor driver) (1/1)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
20/11/30 23:43:19 INFO DAGScheduler: ResultStage 32 (treeAggregate at RowMatrix.scala:419) finished in 0.254 s
20/11/30 23:43:19 INFO DAGScheduler: Job 23 finished: treeAggregate at RowMatrix.scala:419, took 0.264520 s
20/11/30 23:43:19 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:122
20/11/30 23:43:19 INFO DAGScheduler: Got job 24 (treeAggregate at RowMatrix.scala:122) with 1 output partitions
20/11/30 23:43:19 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at RowMatrix.scala:122)
20/11/30 23:43:19 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:43:19 INFO DAGScheduler: Missing parents: List()
20/11/30 23:43:19 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[143] at treeAggregate at RowMatrix.scala:122), which has no missing parents
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 105.6 KB, free 898.8 MB)
20/11/30 23:43:19 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.2 KB, free 898.8 MB)
20/11/30 23:43:19 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:52718 (size: 28.2 KB, free: 899.1 MB)
20/11/30 23:43:19 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
20/11/30 23:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[143] at treeAggregate at RowMatrix.scala:122)
20/11/30 23:43:19 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
20/11/30 23:43:19 WARN TaskSetManager: Stage 33 contains a task of very large size (1661 KB). The maximum recommended task size is 100 KB.
20/11/30 23:43:19 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 1701725 bytes)
20/11/30 23:43:19 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
20/11/30 23:43:19 INFO BlockManager: Found block rdd_95_0 locally
20/11/30 23:43:20 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 16406 bytes result sent to driver
20/11/30 23:43:20 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 147 ms on localhost (executor driver) (1/1)
20/11/30 23:43:20 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
20/11/30 23:43:20 INFO DAGScheduler: ResultStage 33 (treeAggregate at RowMatrix.scala:122) finished in 0.147 s
20/11/30 23:43:20 INFO DAGScheduler: Job 24 finished: treeAggregate at RowMatrix.scala:122, took 0.154555 s
20/11/30 23:44:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_more_30`
20/11/30 23:44:46 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:52718 in memory (size: 28.1 KB, free: 899.2 MB)
20/11/30 23:44:46 INFO CodeGenerator: Code generated in 71.197861 ms
20/11/30 23:44:46 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:52718 in memory (size: 28.2 KB, free: 899.2 MB)
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1504
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1505
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1506
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1507
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1508
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1509
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1510
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1511
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1512
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1513
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1514
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1515
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1516
20/11/30 23:44:46 INFO ContextCleaner: Cleaned shuffle 8
20/11/30 23:44:46 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:52718 in memory (size: 4.7 KB, free: 899.2 MB)
20/11/30 23:44:46 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:52718 in memory (size: 3.7 KB, free: 899.2 MB)
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1613
20/11/30 23:44:46 INFO ContextCleaner: Cleaned accumulator 1614
20/11/30 23:44:46 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:52718 in memory (size: 27.6 KB, free: 899.2 MB)
20/11/30 23:44:46 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:52718 in memory (size: 27.6 KB, free: 899.3 MB)
20/11/30 23:44:46 INFO SparkContext: Starting job: first at PCA.scala:43
20/11/30 23:44:46 INFO DAGScheduler: Got job 25 (first at PCA.scala:43) with 1 output partitions
20/11/30 23:44:46 INFO DAGScheduler: Final stage: ResultStage 34 (first at PCA.scala:43)
20/11/30 23:44:46 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:44:46 INFO DAGScheduler: Missing parents: List()
20/11/30 23:44:46 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[148] at map at PCA.scala:95), which has no missing parents
20/11/30 23:44:46 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 90.6 KB, free 899.2 MB)
20/11/30 23:44:46 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 27.6 KB, free 899.1 MB)
20/11/30 23:44:46 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:52718 (size: 27.6 KB, free: 899.2 MB)
20/11/30 23:44:46 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
20/11/30 23:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[148] at map at PCA.scala:95)
20/11/30 23:44:46 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
20/11/30 23:44:46 WARN TaskSetManager: Stage 34 contains a task of very large size (6333 KB). The maximum recommended task size is 100 KB.
20/11/30 23:44:46 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 6485615 bytes)
20/11/30 23:44:46 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
20/11/30 23:44:46 INFO MemoryStore: Block rdd_112_0 stored as values in memory (estimated size 1770.7 KB, free 897.4 MB)
20/11/30 23:44:46 INFO BlockManagerInfo: Added rdd_112_0 in memory on 127.0.0.1:52718 (size: 1770.7 KB, free: 897.5 MB)
20/11/30 23:44:46 INFO CodeGenerator: Code generated in 35.447336 ms
20/11/30 23:44:46 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_112_0]
20/11/30 23:44:46 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 2541 bytes result sent to driver
20/11/30 23:44:46 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 547 ms on localhost (executor driver) (1/1)
20/11/30 23:44:46 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
20/11/30 23:44:46 INFO DAGScheduler: ResultStage 34 (first at PCA.scala:43) finished in 0.547 s
20/11/30 23:44:46 INFO DAGScheduler: Job 25 finished: first at PCA.scala:43, took 0.556567 s
20/11/30 23:44:46 INFO SparkContext: Starting job: first at RowMatrix.scala:61
20/11/30 23:44:46 INFO DAGScheduler: Got job 26 (first at RowMatrix.scala:61) with 1 output partitions
20/11/30 23:44:46 INFO DAGScheduler: Final stage: ResultStage 35 (first at RowMatrix.scala:61)
20/11/30 23:44:46 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:44:46 INFO DAGScheduler: Missing parents: List()
20/11/30 23:44:46 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[148] at map at PCA.scala:95), which has no missing parents
20/11/30 23:44:46 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 90.6 KB, free 897.3 MB)
20/11/30 23:44:46 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 27.6 KB, free 897.3 MB)
20/11/30 23:44:46 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:52718 (size: 27.6 KB, free: 897.5 MB)
20/11/30 23:44:46 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
20/11/30 23:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[148] at map at PCA.scala:95)
20/11/30 23:44:46 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
20/11/30 23:44:46 WARN TaskSetManager: Stage 35 contains a task of very large size (6333 KB). The maximum recommended task size is 100 KB.
20/11/30 23:44:46 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 6485615 bytes)
20/11/30 23:44:46 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
20/11/30 23:44:46 INFO BlockManager: Found block rdd_112_0 locally
20/11/30 23:44:46 WARN Executor: 1 block locks were not released by TID = 35:
[rdd_112_0]
20/11/30 23:44:46 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 1979 bytes result sent to driver
20/11/30 23:44:46 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 271 ms on localhost (executor driver) (1/1)
20/11/30 23:44:46 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
20/11/30 23:44:46 INFO DAGScheduler: ResultStage 35 (first at RowMatrix.scala:61) finished in 0.271 s
20/11/30 23:44:46 INFO DAGScheduler: Job 26 finished: first at RowMatrix.scala:61, took 0.282066 s
20/11/30 23:44:46 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:419
20/11/30 23:44:46 INFO DAGScheduler: Got job 27 (treeAggregate at RowMatrix.scala:419) with 1 output partitions
20/11/30 23:44:46 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at RowMatrix.scala:419)
20/11/30 23:44:46 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:44:46 INFO DAGScheduler: Missing parents: List()
20/11/30 23:44:46 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[149] at treeAggregate at RowMatrix.scala:419), which has no missing parents
20/11/30 23:44:46 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 91.5 KB, free 897.2 MB)
20/11/30 23:44:46 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 28.1 KB, free 897.2 MB)
20/11/30 23:44:46 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:52718 (size: 28.1 KB, free: 897.5 MB)
20/11/30 23:44:46 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
20/11/30 23:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[149] at treeAggregate at RowMatrix.scala:419)
20/11/30 23:44:46 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
20/11/30 23:44:47 WARN TaskSetManager: Stage 36 contains a task of very large size (6333 KB). The maximum recommended task size is 100 KB.
20/11/30 23:44:47 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6485623 bytes)
20/11/30 23:44:47 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
20/11/30 23:44:47 INFO BlockManager: Found block rdd_112_0 locally
20/11/30 23:44:47 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 5857 bytes result sent to driver
20/11/30 23:44:47 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 558 ms on localhost (executor driver) (1/1)
20/11/30 23:44:47 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
20/11/30 23:44:47 INFO DAGScheduler: ResultStage 36 (treeAggregate at RowMatrix.scala:419) finished in 0.559 s
20/11/30 23:44:47 INFO DAGScheduler: Job 27 finished: treeAggregate at RowMatrix.scala:419, took 0.566528 s
20/11/30 23:44:47 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:122
20/11/30 23:44:47 INFO DAGScheduler: Got job 28 (treeAggregate at RowMatrix.scala:122) with 1 output partitions
20/11/30 23:44:47 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at RowMatrix.scala:122)
20/11/30 23:44:47 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:44:47 INFO DAGScheduler: Missing parents: List()
20/11/30 23:44:47 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[150] at treeAggregate at RowMatrix.scala:122), which has no missing parents
20/11/30 23:44:47 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 105.6 KB, free 897.1 MB)
20/11/30 23:44:47 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 28.2 KB, free 897.1 MB)
20/11/30 23:44:47 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:52718 (size: 28.2 KB, free: 897.4 MB)
20/11/30 23:44:47 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
20/11/30 23:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[150] at treeAggregate at RowMatrix.scala:122)
20/11/30 23:44:47 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
20/11/30 23:44:47 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:52718 in memory (size: 27.6 KB, free: 897.5 MB)
20/11/30 23:44:47 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:52718 in memory (size: 28.1 KB, free: 897.5 MB)
20/11/30 23:44:47 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:52718 in memory (size: 27.6 KB, free: 897.5 MB)
20/11/30 23:44:47 WARN TaskSetManager: Stage 37 contains a task of very large size (6333 KB). The maximum recommended task size is 100 KB.
20/11/30 23:44:47 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6485623 bytes)
20/11/30 23:44:47 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
20/11/30 23:44:47 INFO BlockManager: Found block rdd_112_0 locally
20/11/30 23:44:47 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 16406 bytes result sent to driver
20/11/30 23:44:47 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 431 ms on localhost (executor driver) (1/1)
20/11/30 23:44:47 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
20/11/30 23:44:47 INFO DAGScheduler: ResultStage 37 (treeAggregate at RowMatrix.scala:122) finished in 0.431 s
20/11/30 23:44:47 INFO DAGScheduler: Job 28 finished: treeAggregate at RowMatrix.scala:122, took 0.439146 s
20/11/30 23:45:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `tbl_num_no_rdms`
20/11/30 23:45:12 INFO CodeGenerator: Code generated in 45.08739 ms
20/11/30 23:45:12 INFO SparkContext: Starting job: first at PCA.scala:43
20/11/30 23:45:12 INFO DAGScheduler: Got job 29 (first at PCA.scala:43) with 1 output partitions
20/11/30 23:45:12 INFO DAGScheduler: Final stage: ResultStage 38 (first at PCA.scala:43)
20/11/30 23:45:12 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:45:12 INFO DAGScheduler: Missing parents: List()
20/11/30 23:45:12 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[155] at map at PCA.scala:95), which has no missing parents
20/11/30 23:45:12 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 90.6 KB, free 897.3 MB)
20/11/30 23:45:12 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 27.6 KB, free 897.3 MB)
20/11/30 23:45:12 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:52718 (size: 27.6 KB, free: 897.5 MB)
20/11/30 23:45:12 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
20/11/30 23:45:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[155] at map at PCA.scala:95)
20/11/30 23:45:12 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
20/11/30 23:45:12 WARN TaskSetManager: Stage 38 contains a task of very large size (14877 KB). The maximum recommended task size is 100 KB.
20/11/30 23:45:12 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 15234103 bytes)
20/11/30 23:45:12 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
20/11/30 23:45:13 INFO MemoryStore: Block rdd_129_0 stored as values in memory (estimated size 4.1 MB, free 893.2 MB)
20/11/30 23:45:13 INFO BlockManagerInfo: Added rdd_129_0 in memory on 127.0.0.1:52718 (size: 4.1 MB, free: 893.4 MB)
20/11/30 23:45:13 INFO CodeGenerator: Code generated in 31.072516 ms
20/11/30 23:45:13 WARN Executor: 1 block locks were not released by TID = 38:
[rdd_129_0]
20/11/30 23:45:13 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 2505 bytes result sent to driver
20/11/30 23:45:13 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 1365 ms on localhost (executor driver) (1/1)
20/11/30 23:45:13 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
20/11/30 23:45:13 INFO DAGScheduler: ResultStage 38 (first at PCA.scala:43) finished in 1.367 s
20/11/30 23:45:13 INFO DAGScheduler: Job 29 finished: first at PCA.scala:43, took 1.378959 s
20/11/30 23:45:13 INFO SparkContext: Starting job: first at RowMatrix.scala:61
20/11/30 23:45:13 INFO DAGScheduler: Got job 30 (first at RowMatrix.scala:61) with 1 output partitions
20/11/30 23:45:13 INFO DAGScheduler: Final stage: ResultStage 39 (first at RowMatrix.scala:61)
20/11/30 23:45:13 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:45:13 INFO DAGScheduler: Missing parents: List()
20/11/30 23:45:13 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[155] at map at PCA.scala:95), which has no missing parents
20/11/30 23:45:13 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 90.6 KB, free 893.1 MB)
20/11/30 23:45:13 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 27.6 KB, free 893.1 MB)
20/11/30 23:45:13 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:52718 (size: 27.6 KB, free: 893.4 MB)
20/11/30 23:45:13 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
20/11/30 23:45:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[155] at map at PCA.scala:95)
20/11/30 23:45:13 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
20/11/30 23:45:13 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:52718 in memory (size: 27.6 KB, free: 893.4 MB)
20/11/30 23:45:13 WARN TaskSetManager: Stage 39 contains a task of very large size (14877 KB). The maximum recommended task size is 100 KB.
20/11/30 23:45:13 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 15234103 bytes)
20/11/30 23:45:13 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
20/11/30 23:45:14 INFO BlockManager: Found block rdd_129_0 locally
20/11/30 23:45:14 WARN Executor: 1 block locks were not released by TID = 39:
[rdd_129_0]
20/11/30 23:45:14 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 1943 bytes result sent to driver
20/11/30 23:45:14 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 651 ms on localhost (executor driver) (1/1)
20/11/30 23:45:14 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
20/11/30 23:45:14 INFO DAGScheduler: ResultStage 39 (first at RowMatrix.scala:61) finished in 0.652 s
20/11/30 23:45:14 INFO DAGScheduler: Job 30 finished: first at RowMatrix.scala:61, took 0.661268 s
20/11/30 23:45:14 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:419
20/11/30 23:45:14 INFO DAGScheduler: Got job 31 (treeAggregate at RowMatrix.scala:419) with 1 output partitions
20/11/30 23:45:14 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at RowMatrix.scala:419)
20/11/30 23:45:14 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:45:14 INFO DAGScheduler: Missing parents: List()
20/11/30 23:45:14 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[156] at treeAggregate at RowMatrix.scala:419), which has no missing parents
20/11/30 23:45:14 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 91.5 KB, free 893.1 MB)
20/11/30 23:45:14 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 28.1 KB, free 893.1 MB)
20/11/30 23:45:14 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:52718 (size: 28.1 KB, free: 893.4 MB)
20/11/30 23:45:14 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
20/11/30 23:45:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[156] at treeAggregate at RowMatrix.scala:419)
20/11/30 23:45:14 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
20/11/30 23:45:14 WARN TaskSetManager: Stage 40 contains a task of very large size (14877 KB). The maximum recommended task size is 100 KB.
20/11/30 23:45:14 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 15234111 bytes)
20/11/30 23:45:14 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)
20/11/30 23:45:14 INFO BlockManager: Found block rdd_129_0 locally
20/11/30 23:45:15 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 5930 bytes result sent to driver
20/11/30 23:45:15 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 1156 ms on localhost (executor driver) (1/1)
20/11/30 23:45:15 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
20/11/30 23:45:15 INFO DAGScheduler: ResultStage 40 (treeAggregate at RowMatrix.scala:419) finished in 1.156 s
20/11/30 23:45:15 INFO DAGScheduler: Job 31 finished: treeAggregate at RowMatrix.scala:419, took 1.163549 s
20/11/30 23:45:15 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:122
20/11/30 23:45:15 INFO DAGScheduler: Got job 32 (treeAggregate at RowMatrix.scala:122) with 1 output partitions
20/11/30 23:45:15 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at RowMatrix.scala:122)
20/11/30 23:45:15 INFO DAGScheduler: Parents of final stage: List()
20/11/30 23:45:15 INFO DAGScheduler: Missing parents: List()
20/11/30 23:45:15 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[157] at treeAggregate at RowMatrix.scala:122), which has no missing parents
20/11/30 23:45:15 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 105.6 KB, free 893.0 MB)
20/11/30 23:45:15 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 28.2 KB, free 893.0 MB)
20/11/30 23:45:15 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:52718 (size: 28.2 KB, free: 893.4 MB)
20/11/30 23:45:15 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
20/11/30 23:45:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[157] at treeAggregate at RowMatrix.scala:122)
20/11/30 23:45:15 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
20/11/30 23:45:15 WARN TaskSetManager: Stage 41 contains a task of very large size (14877 KB). The maximum recommended task size is 100 KB.
20/11/30 23:45:15 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 15234111 bytes)
20/11/30 23:45:15 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)
20/11/30 23:45:15 INFO BlockManager: Found block rdd_129_0 locally
20/11/30 23:45:16 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 16479 bytes result sent to driver
20/11/30 23:45:16 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 987 ms on localhost (executor driver) (1/1)
20/11/30 23:45:16 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
20/11/30 23:45:16 INFO DAGScheduler: ResultStage 41 (treeAggregate at RowMatrix.scala:122) finished in 0.988 s
20/11/30 23:45:16 INFO DAGScheduler: Job 32 finished: treeAggregate at RowMatrix.scala:122, took 0.998943 s
